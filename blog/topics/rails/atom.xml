<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Topic: Rails | Hungry and Foolish]]></title>
  <link href="http://vladigleba.github.io/blog/topics/rails/atom.xml" rel="self"/>
  <link href="http://vladigleba.github.io/"/>
  <updated>2014-06-01T14:58:17-07:00</updated>
  <id>http://vladigleba.github.io/</id>
  <author>
    <name><![CDATA[Vladi Gleba]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Do Autocomplete in Rails Using Redis]]></title>
    <link href="http://vladigleba.github.io/blog/2014/05/30/how-to-do-autocomplete-in-rails-using-redis/"/>
    <updated>2014-05-30T10:40:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/05/30/how-to-do-autocomplete-in-rails-using-redis</id>
    <content type="html"><![CDATA[<p>A few days ago, I added search functionality to <a href="http://phindee.com/">Phindee</a> so users can quickly find information about a particular happy hour. Search that is well-done often comes with autocomplete, and Phindee is no exception.</p>

<!-- more -->


<p>Autocomplete in Phindee does a couple of things for the user: 1) it reduces typing, 2) it lets the user quickly know if a specific happy hour is in the database, 3) it allows her to quickly find a particular happy hour that <em>is</em> in the database, and 4) it lets him know if the happy hour is currently happening because it will have a green circle next to it if that’s the case.</p>

<p>What makes this work behind the scenes is an open-source, in-memory, key-value store called <a href="https://github.com/antirez/redis/">Redis</a>. Because it’s in-memory, Redis is fast, which makes it perfect for autocompletion. I’ve known about Redis for a while now, but never had a need to use it, so I’m glad the opportunity finally presented itself. But now that I’ve had a chance to work with it, I’d like to explain how the autocomplete functionality works behind the scenes, and hopefully, teach you a few things for your own projects.</p>

<p>Before we go on, it’s important that you have a basic understanding of Redis. If you’re never used it before, I recommend going through the <a href="http://try.redis.io/">interactive tutorial</a> on their website; it will help you understand what it’s for, what it can do, and how to use it. Pay special attention to the section on sorted sets because that’s what we’ll be using for autocompletion.</p>

<h1>Installing Redis</h1>

<p>If you’re on a Mac, you can easily install Redis using <a href="https://github.com/Homebrew/homebrew">Homebrew</a> by running the following command:</p>

<p><code>bash
brew install redis
</code></p>

<p>When it finishes, it’ll give you the command to start the Redis server:</p>

<p><code>bash
redis-server /usr/local/etc/redis.conf
</code></p>

<p>You can then access the Redis command-line by running <code>redis-cli</code>, which allows you to play around with various Redis commands to see how they work.</p>

<p>Next, you’ll need to hook Redis up with your Rails app, and you can do this by adding the following line to your ‘Gemfile’:</p>

<p><code>ruby Gemfile
gem 'redis', '~&gt; 3.0.7'
</code></p>

<p>Then run <code>bundle</code> to install it.</p>

<h1>Defining a Model for Redis to Work With</h1>

<p>First thing we’ll need to do is create an initializer file for setting up our Redis connection. Go ahead and create a file called <code>redis.rb</code> inside your app’s <code>/config/initializers</code> directory. Then add the following line into it:</p>

<p><code>ruby redis.rb
$redis = Redis.new
</code></p>

<p>This creates a global variable called <code>$redis</code> to make it easy for us to access Redis through out our app.</p>

<p>Next, we’ll create a new file called <code>search_suggestion.rb</code> inside the <code>/app/models</code> directory. It will contain the code that seeds our Redis database and retrieves a list of suggestions. To start things off, add the following code into it:</p>

<p>``` ruby search_suggestion.rb
class SearchSuggestion</p>

<p>  def self.seed</p>

<pre><code>Place.find_each do |place|
  name = place.name
  1.upto(name.length - 1) do |n|
    prefix = name[0, n]
    $redis.zadd 'search-suggestions:#{prefix.downcase}', 1, name.downcase
  end
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>This creates a class called <code>SearchSuggestion</code> with a class method called <code>seed()</code>. Notice that this class doesn’t inherit from <code>ActiveRecord::Base</code>, which is the base class that the models you create with <code>rails g model ...</code> inherit from. We don’t need it because we’ll be using Redis instead of ActiveRecord. (By the way, we’re defining a class method instead of an instance method because the logic in this method relates to the class itself, not a specific instance of it.)</p>

<h2>Code Walk-Through</h2>

<p>Alright, now let’s go over the code. Phindee has a model called <code>Place</code> for storing all the places that have a happy hour, and I’m simply looping over each record stored in it. The reason why I’m doing <code>Place.find_each</code> instead of <code>Place.all.each</code> is the <code>find_each()</code> method works in batches of 1000. This means that if I have thousands of records in my database, <code>find_each()</code> will load into memory only 1000 at a time, instead of loading them all at once and possibly overwhelming the server, which is the case with <code>Place.all.each</code>.</p>

<p>For each place, I’m using the <code>upto()</code> method to loop over the place’s name n times, where n is the number of characters in the name minus 1 (you’ll see why we’re doing minus 1 later). For example, let’s say the place name is “via delizia”. Our n value would be 10 because the length of the name is 11, but minus 1 brings it down to 10, so we would iterate over the name 10 times.</p>

<p>On the first iteration, n would be 1 and the <code>prefix</code> variable would be set to the string “v” since we’re extracting the characters from 0 to 1. Then the Redis <a href="http://redis.io/commands/zadd"><code>ZADD</code> command</a> is used to create a Sorted Set called “search-suggestions:v” since the variable <code>prefix</code> is set to “v” on the first iteration. (I’m prefixing the set name with “search-suggestions” to keep things organized, but this is not strictly necessary).</p>

<p>Sorted Sets are very similar to Sets because they both store collections of strings, but a Sorted Set also stores an associated score with each string that is then used for sorting. So if we go back to the code, you’ll see that <code>ZADD</code> initializes the set “search-suggestions:v” with a score of 1 and a value of “via delizia”&mdash;the place’s full name.</p>

<p>On the second iteration, a new set will be created called “search-suggestions:vi” since we’re now extracting the characters from 0 to 2, and this initializes the variable <code>prefix</code> to “vi”.  The set itself is then initialized to a score of 1 and a string of “via delizia”, just like the first time.</p>

<p>The same process is then repeated on the subsequent iterations as well. After the 10th iteration, we’ll have 10 different sets initialized to a score of 1 and a string of “via delizia”, like so:</p>

<p>``` bash
&lsquo;search-suggestions:v&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:vi&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via &rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via d&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via de&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via del&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via deli&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via deliz&rsquo; => [&lsquo;via delizia&rsquo;, 1]</p>

<p>&lsquo;search-suggestions:via delizi&rsquo; => [&lsquo;via delizia&rsquo;, 1]
```</p>

<p>Note that we don’t create a last set called “search-suggestions:via delizia” because there is no point in returning “via delizia” as a suggested term when a user types “via delizia”. That’s why we added the minus 1 to the length of the name.</p>

<p>By the way, all the scores are identical right now, but they can be incremented later to increase the ranking of popular search terms, although I won&rsquo;t be covering how to do this here.</p>

<p>Let’s now assume the second place name is “vault martini”. This means that on the very first iteration, with the <code>prefix</code> variable set to “v” once again, there will be no new set created since we already have a set called “search-suggestions:v”. <code>ZADD</code> will recognize this and add to the already existing set, instead. This means that the set “search-suggestions:v” will now hold two keys:</p>

<p><code>
'search-suggestions:v' =&gt; [['via delizia', 1], ['vault martini', 1]]
</code></p>

<p>And now you can see how autocompletion will work. Whenever a user types “v” in the search bar, we can return a list of search suggestions simply by returning the values in the “search-suggestions:v” set. There is no need for expensive queries that search through the entire database and look for matches. Instead, we find what we’re looking for right away. That&rsquo;s the beauty of Redis (and other key-value stores).</p>

<h2>Extracting Values from a Sorted Set</h2>

<p>But how do we extract values from a set? Well, Redis has a command called <a href="http://redis.io/commands/zrevrange"><code>ZREVRANGE</code></a> that does just that. It returns a range of elements sorted by score (with the highest scores listed first). Go ahead and add the following to <code>search_suggestion.rb</code>:</p>

<p>``` ruby search_suggestion.rb
&hellip;</p>

<p>  def self.terms_for(prefix)</p>

<pre><code>$redis.zrevrange 'search-suggestions:#{prefix.downcase}', 0, 9
</code></pre>

<p>  end</p>

<p>&hellip;
```</p>

<p>This function accepts a <code>prefix</code> variable and uses <code>ZREVRANGE</code> to return the first 10 elements of a sorted set containing the specified <code>prefix</code> value. We&rsquo;ll use it later to return a list of search suggestions to the user.</p>

<h1>Creating a Rake Task to Seed Redis</h1>

<p>In order to make it easy for us to seed Redis from the command line, we&rsquo;ll create a <a href="https://github.com/jimweirich/rake">Rake</a> task that calls the <code>seed()</code> method we defined earlier. (If you&rsquo;re new to Rake, I highly recommend watching the <a href="http://railscasts.com/episodes/66-custom-rake-tasks">Railscasts episode</a> about it.) Go ahead and create a new file called <code>search_suggestions.rake</code> inside your app&rsquo;s <code>/lib/tasks</code> directory, and add the following into it:</p>

<p>``` ruby search_suggestions.rake
namespace :search_suggestions do</p>

<p>  desc &lsquo;Generate search suggestions&rsquo;
  task index: :environment do</p>

<pre><code>SearchSuggestion.seed
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>The code is simple. We&rsquo;re creating a task called <code>index</code> and making it dependent on a Rake task provided by Rails called <code>environment</code>, which loads the Rails environment and gives us access to our <code>SearchSuggestion</code> class. Then we&rsquo;re just calling the <code>seed()</code> method we defined earlier to seed Redis. (We wrap this up inside a namespace called <code>search_suggestions</code> to keep things neat and organized.)</p>

<p>And now we can <code>cd</code> into our app&rsquo;s root directory and call this task from the command line, like so:</p>

<p><code>bash
rake search_suggestions:index
</code></p>

<p>You can then go into the Rails console with <code>rails c</code> and run some Redis commands to see if it worked. For example, if I defined a set called &ldquo;search-suggestions:v&rdquo; earlier, I can run the <code>ZREVRANGE</code> command to return the first 10 elements:</p>

<p><code>bash
$redis.zrange 'search-suggestions:v', 0, 9, with_scores: true
=&gt; [["vault martini", 1.0], ["via delizia", 1.0], ["vino bar", 1.0]]
</code></p>

<p>Note that if you want Redis to return the values along with their scores, you need to pass an argument called <code>with_scores</code> and set it to <code>true</code>; otherwise, Redis omits the scores.</p>

<h1>Setting Up the Front-End</h1>

<p>Now that we have the back-end functionality setup, it’s time to set up the front-end. We’ll use the jQueryUI <a href="http://api.jqueryui.com/autocomplete/">autocomplete widget</a> due to its simplicity and ease of use. We could include it in our app simply by adding the following to our <code>/app/assets/javascripts/application.js</code> file:</p>

<p><code>javascript application.js
//= require jquery-ui
</code></p>

<p>but this will include the entire library with all the widgets. I don’t like code bloat and prefer to include only the code that I actually need, so we&rsquo;ll take another route.</p>

<h2>Keeping Things Slim</h2>

<p>Head over to the jQueryUI <a href="http://jqueryui.com/download/">download page</a> and under “Components”, deselect the “Toggle All” option, which will deselect all the checkboxes. Then scroll down to the “Widgets” section, select “Autocomplete”, and you’ll see a few other necessary dependencies get selected automatically. Then press “Download”.</p>

<p>If you open the folder it downloaded and go into its <code>/js</code> directory, you’ll see a file that starts with “jquery-ui-” and ends with a “.custom.js” extension.  Open it and copy its code. Then head over to your app, create a new file called <code>autocomplete.js</code> inside the <code>/app/assets/javascripts</code> directory, and paste that code into it.</p>

<p>Now go back to the folder you just downloaded, go into its <code>/css</code> directory, find a file with a “.custom.css” extension, open it, and copy its code. Then create another file called <code>autocomplete.css</code> inside your app’s <code>/app/assets/stylesheets</code> directory and paste the code into it.</p>

<p>Now we have the code we need and no more.</p>

<h2>Hooking It up with HTML</h2>

<p>We&rsquo;re ready to connect the autocomplete code we just added to our app&rsquo;s HTML. In Phindee, I have a simple form with a search image and an input field that needs the autocomplete functionality:</p>

<p>``` erb
&hellip;</p>

<p><form class="search-form”>
  &lt;%= image_tag asset_path(&lsquo;search-icon.svg&rsquo;), class: &lsquo;search-icon&rsquo; %>
  <input type="text" class=“search-field" />
</form></p>

<p>&hellip;
```</p>

<p>In another file, I have the following CoffeeScript code that hooks up the autocomplete widget to the input field I just mentioned above:</p>

<p>``` coffeescript
&hellip;</p>

<p>  $(&lsquo;.search-field&rsquo;).autocomplete</p>

<pre><code>appendTo: '.search-form',
source: '/search_suggestions'
</code></pre>

<p>&hellip;
```</p>

<p>I’m simply calling the jQueryUI-provided <code>autocomplete()</code> method on the input field I&rsquo;m interested in. I then use the <code>appendTo</code> option to specify that the autocomplete drop-down should be appended to the form itself. Finally, I’m using <code>source</code> to specify the URL path the autocomplete widget will use to get a list of search suggestions that will be displayed in the drop-down. I chose a path called “/search_suggestions”, but you can choose any path you want.</p>

<h2>How It Works</h2>

<p>If you look at the <a href="http://api.jqueryui.com/autocomplete/#option-source">documentation</a> for <code>source</code>, you’ll see that it can accept the search suggestions as an array of strings, a string pointing to a URL that <em>returns</em> an array of strings, or a function with a response callback that also returns an array of strings. We’re using a string pointing to a URL since this fits our needs perfectly.</p>

<p>This is how it will work. The widget will take whatever is typed in the search field and append it to a variable called “term”, which itself will get appended to the URL path we specified in <code>source</code>. Then it’ll make a GET request to the URL and expect our server to respond with the search suggestions rendered as an array of strings in the JSON format. So for example, if the user types in “v”, the widget will make a GET request to “/search_suggestions?term=v”, and it’ll expect the server to respond with something like <code>["via delizia","vault martini”]</code>.</p>

<p>Our server doesn’t yet know how to respond to a URL like this. Let’s set it up.</p>

<h1>Creating a Controller to Handle Requests</h1>

<p>First, we’ll create a controller that takes the search phrase the user types in, passes it on to the <code>terms_for()</code> method we defined in <code>search_suggestion.rb</code>, and returns the resulting list of suggestions back to the user. We&rsquo;ll call it <code>search_suggestions</code>:</p>

<p><code>bash
rails g controller search_suggestions
</code></p>

<p>This will create a new file called <code>search_suggestions_controller.rb</code>. Open it and add the following code inside the <code>SearchSuggestionsController</code> class:</p>

<p>``` ruby search_suggestions_controller.rb
&hellip;</p>

<p>  def index</p>

<pre><code>render json: SearchSuggestion.terms_for(params[:term])
</code></pre>

<p>  end</p>

<p>&hellip;
```</p>

<p>We extract the value of the <code>term</code> variable using <code>params[:term]</code>, pass it on to the <code>terms_for()</code> method, and tell Rails to render the response in JSON format. Kid stuff.</p>

<p>Then open your app’s <code>/config/routes.rb</code> file and add the following line into it:</p>

<p>``` ruby routes.rb
&hellip;</p>

<p>  match &lsquo;/search_suggestions&rsquo;, to: &lsquo;search_suggestions#index&rsquo;, via: :get</p>

<p>&hellip;
```</p>

<p>This maps our <code>index</code> controller to the path we specified earlier in <code>source</code>, and our server now knows how to respond to a URL like &ldquo;/search_suggestions?term=v&rdquo;.</p>

<p>I think we’re ready for the moment of truth. Restart the rails server, type something in the search field, and if all is well with the world, you should see a drop-down menu with a list of search suggestions. If you don’t, you&rsquo;ll need to do some debugging to figure out what&rsquo;s wrong.</p>

<h1>Making It Work on a VPS</h1>

<p>Installing Redis on a VPS isn’t as easy as running <code>brew install redis</code>, but it’s not too bad. DigitalOcean has a <a href="https://www.digitalocean.com/community/articles/how-to-install-and-use-redis">nice tutorial</a> on the subject. I used it myself to get Redis installed on the server running Phindee, and it worked without a hiccup. I highly recommend it.</p>

<p>Once you have it installed, you’ll need to run the <code>index</code> task we wrote earlier to seed the database with data. If you’re using Capistrano, you can use the following task to run it from your local computer:</p>

<p>``` ruby
desc &lsquo;Seed the redis database (search suggestions)&rsquo;
task :seed_redis do
  on roles(:app) do</p>

<pre><code>within '#{current_path}' do
  with rails_env: :production do
    execute :rake, 'search_suggestions:index'
  end
end
</code></pre>

<p>  end
end
```</p>

<p>If you’re new to Capistrano, feel free to read through an <a href="/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks/">earlier post</a> I wrote, which explains what it is and how you can use it. Or if you’re new to deployment in general, you’re welcome to go through my <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">6-part series</a>, which covers everything from setting up and securing a server to configuring Nginx, Unicorn, and Capistrano.</p>

<p>Alright, that&rsquo;s all I have. Stay hungry. Stay foolish.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 6: Writing Capistrano Tasks]]></title>
    <link href="http://vladigleba.github.io/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks/"/>
    <updated>2014-04-10T08:42:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks</id>
    <content type="html"><![CDATA[<p>It’s been a long time coming, but we finally reached the point where we can deploy our app to our VPS and have it be available on the internet for viewing. We configured Capistrano in the <a href="/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/">previous post</a>, and now we’ll actually use it for the deploy. Just like in the previous posts, I’ll be going over how I have things setup for <a href="http://phindee.com/">Phindee</a> to help illustrate the concepts.</p>

<!-- more -->


<p>You might already know this, but Capistrano does much of its work with the help of tasks. When we previously ran <code>cap install</code>, we actually invoked a task named <code>install</code> that created various files and directories; if you’re interested, you can see its code <a href="https://github.com/capistrano/capistrano/blob/master/lib/capistrano/tasks/install.rake">on GitHub</a>. Similarly, we can write our own tasks to help us automate various things.</p>

<p>When I was deploying Phindee, I created a file called <code>setup.cap</code> inside the app’s local <code>/lib/capistrano/tasks</code> directory. Go ahead and do the same for your app, and add the following code into it:</p>

<p>``` ruby setup.cap
namespace :setup do</p>

<p>  desc &ldquo;Upload database.yml file.&rdquo;
  task :upload_yml do</p>

<pre><code>on roles(:app) do
  execute "mkdir -p #{shared_path}/config"
  upload! StringIO.new(File.read("config/database.yml")), "#{shared_path}/config/database.yml"
end
</code></pre>

<p>  end</p>

<p>  desc &ldquo;Seed the database.&rdquo;
  task :seed_db do</p>

<pre><code>on roles(:app) do
  within "#{current_path}" do
    with rails_env: :production do
      execute :rake, "db:seed"
    end
  end
end
</code></pre>

<p>  end</p>

<p>  desc &ldquo;Symlinks config files for Nginx and Unicorn.&rdquo;
  task :symlink_config do</p>

<pre><code>on roles(:app) do
  execute "rm -f /etc/nginx/sites-enabled/default"

  execute "ln -nfs #{current_path}/config/nginx.conf /etc/nginx/sites-enabled/#{fetch(:application)}"
  execute "ln -nfs #{current_path}/config/unicorn_init.sh /etc/init.d/unicorn_#{fetch(:application)}"
</code></pre>

<p>   end
  end</p>

<p>end
```</p>

<p>The first thing you’ll notice is we’re organizing all of the tasks here under a namespace called <code>:setup</code>. It’s not strictly necessary, but I just like to keep things organized. If the code seems overwhelming, don’t worry&mdash;I’ll explain everything.</p>

<h1>Uploading Database Info</h1>

<p>We’ll get a feel for how tasks work and what they’re capable of doing by running the first task in this file, which will simply upload our <code>database.yml</code> file to our server. But before we run it, we first need to add <code>database.yml</code> to our <code>.gitignore</code> file to let Git know we don’t want it tracked and uploaded to GitHub from now on. Why? Because we’ll be adding our database password into it, and it’s generally not a good idea to upload passwords to your GitHub repository. Below is how my <code>.gitignore</code> file looks like (it&rsquo;s usually located in your app&rsquo;s root directory, but if it&rsquo;s not there, go ahead and create it):</p>

<p>``` text .gitignore</p>

<h1>Ignore bundler config.</h1>

<p>/.bundle</p>

<h1>Ignore the default SQLite database.</h1>

<p>/db/<em>.sqlite3
/db/</em>.sqlite3-journal</p>

<h1>Ignore log, doc, and tmp directories</h1>

<p>/log/*.log
/tmp
/doc</p>

<h1>Ignore .DS_Store files on Mac</h1>

<p>.DS_Store</p>

<h1>Ignore database.yml file to prevent password leakage</h1>

<p>/config/database.yml
```</p>

<p>You can see that in addition to ignoring the <code>database.yml</code> file, I’m also ignoring lots of other files as well, especially the annoying <code>.DS_Store</code> files that the Mac OS loves to create.</p>

<p>With that out of the way, we can now safely open up <code>database.yml</code> and add our database parameters to the file&rsquo;s production section. We’ll only need to modify the <code>database</code>, <code>username</code>, and <code>password</code> keys, and everything else can be left the way it is. Make sure you set these to the database name, username, and password you created in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>.</p>

<p>Then run the following command inside your app’s local root directory:</p>

<p><code>bash
cap production setup:upload_yml
</code></p>

<p>This tells Capistrano to execute the <code>upload_yml</code> task inside the <code>setup</code> namespace using the <code>production.rb</code> file configurations. (If we had the <code>stage.rb</code> file setup, we could’ve ran <code>cap stage setup:upload_yml</code> to execute this task on our staging environment instead.) We can verify that the command uploaded the <code>database.yml</code> file to our server by logging in and outputting the contents of the file:</p>

<p><code>bash
cat /var/www/phindee/shared/config/database.yml
</code></p>

<p>This is obviously a trivial task, but it shows how powerful Capistrano can be. A few keystrokes allowed us to create a specific directory structure on our server and upload a file from our local computer. Neat stuff&mdash;and it will only get better.</p>

<p>Alright, let’s now switch gears and learn about the syntax that made all of this possible.</p>

<h1>Understanding SSHKit</h1>

<p>Capistrano 3 uses the Rake DSL (Domain Specific Language), which means if you ever wrote Rake tasks, you&rsquo;ll be in familiar territory when writing Capistrano tasks; the only new thing you&rsquo;ll need to learn about is SSHKit and the various methods it provides. <a href="https://github.com/capistrano/sshkit">SSHKit</a> was actually developed and released with Capistrano 3, and it’s basically a lower-level tool that provides methods for connecting and interacting with remote servers; it does all the heavy lifting for Capistrano, in other words. There are four main methods you need to know about:</p>

<ul>
<li><code>on()</code>: specifies the server to run on</li>
<li><code>within()</code>: specifies the directory path to run in</li>
<li><code>as()</code>: specifies the user to run as</li>
<li><code>with()</code>: specifies the environment variables to run with</li>
</ul>


<p>Typically, you’ll start a task by using an <code>on()</code> method to specify the server on which you want your commands to run. Then you can use any combination of <code>as()</code>, <code>within()</code>, and <code>with()</code> methods, which are repeatable and stackable in any order, to provide additional details. For example, the <code>upload_yml</code> task we ran in <code>setup.cap</code> uses the <code>on()</code> method to specify that the resulting block of code should only be run on the application server. The <code>seed_db</code> task right below it has <em>three</em> parameters that specify how the resulting statement will run; it uses <code>on()</code>, <code>within()</code>, and <code>with()</code> to specify that the statement should only run <em>on</em> the application server, <em>within</em> the path specified, and <em>with</em> certain environment variables set.</p>

<p>Obviously, if SSHKit gives you methods to specify certain parameters that must be met before the actual statements are run, it should also give you methods to help you run those statements. That’s exactly what it does, and below are those methods:</p>

<ul>
<li><code>execute()</code>: the workhorse that runs the commands on your server</li>
<li><code>upload()</code>: uploads a file from your local computer to your remote server</li>
<li><code>capture()</code>: executes a command and returns its output as a string</li>
<li><code>puts()</code>: writes the output returned by <code>capture()</code> to the screen</li>
<li><code>background()</code>: runs a command in the background</li>
<li><code>test()</code>: can be used for control flow since it works like the <code>test</code> command-line utility in Unix and returns false if its expression exits with a non-zero value</li>
</ul>


<p>Armed with this knowledge, we’re now better equipped to understand the three tasks in <code>setup.cap</code>.</p>

<h1>Task Walk-Through</h1>

<p>The <code>upload_yml</code> task, for example, is run on the application server only, and its first statement uses the <code>execute()</code> method to run <code>mkdir -p</code>, which creates the following directory structure inside <code>/var</code>, if it doesn’t already exist:</p>

<pre><code>├── www
  └── phindee
    └── shared
      └── config
</code></pre>

<p>The <code>shared_path</code> variable evaluates to <code>/var/www/phindee/shared</code>, since it takes the path we specified in <code>deploy_to</code> and appends the <code>/shared</code> directory to the end of it (<a href="https://github.com/capistrano/capistrano/blob/aeab6b6a1e5c5e654f35321dcd7438a0659864d0/lib/capistrano/dsl/paths.rb#L60">see the code</a>). We then append the <code>/config</code> directory to the end of that.</p>

<p>The next statement uses <code>upload()</code> to upload our <code>database.yml</code> file to the directory we just created above. <code>File.read()</code> returns the file&rsquo;s contents as a string, which <code>StringIO.new()</code> takes and turns into a file. We then use this file as our source and <code>#{shared_path}/config/database.yml</code> as our destination. By the way, <code>upload()</code> has the bang symbol (!) because that’s how it’s defined in SSHKit, and it&rsquo;s just a convention letting us know that the method will block until it finishes.</p>

<p>The <code>seed_db</code> task does exactly what it says&mdash;seeds the database with data by running <code>rake db:seed</code>. The <code>current_path</code> variable takes the <code>deploy_to</code> path and appends <code>/current</code> to it, which will result in <code>/var/www/phindee/current</code>. This is where the seed statement will run on the application server with the <code>rails_env</code> variable set to <code>:production</code>.</p>

<p>But in order to ensure <code>rake</code> runs with the proper environment variables set, we have to use <code>rake</code> as a symbol and pass <code>db:seed</code> as a string; otherwise, the environment variables won&rsquo;t be set. This format will also be necessary whenever you’re running any other Rails-specific commands that rely on certain environment variables being set (see <a href="https://github.com/capistrano/sshkit#the-command-map">this section</a> of the SSHKit README to learn more).</p>

<p>The final <code>:symlink_config</code> task does a couple ofthings. First, it removes the default configuration file for Nginx (<code>/etc/nginx/sites-enabled/default</code>) and replaces it with a symlink to our own configuration file (<code>nginx.conf</code>). Then it also creates a symlink to our <code>unicorn_init.sh</code> script that helps us manage Unicorn, but this time inside <code>/etc/init.d</code>, which is the place where Ubuntu stores scripts for managing various services (a similar script for managing Nginx was already added there when we ran <code>apt-get</code>). Notice we’re using <code>fetch()</code> in both cases, which simply retrieves the value of a variable initialized by <code>set()</code>, to name our files after our application name.</p>

<p>These three tasks just merely scratch the surface of what’s possible, however. I recommend you take a look at SSHKit’s <a href="https://github.com/capistrano/sshkit/blob/master/EXAMPLES.md">example page</a> to learn more; I found it to be an invaluable tool in helping me better understand how all the different methods work together.</p>

<h1>Finishing Touches</h1>

<p>We’re almost ready for our deploy. There’s just one more file we need to add to <code>/lib/capistrano/tasks</code> called <code>deploy.cap</code>. Below is the code I have in mine:</p>

<p>``` ruby deploy.cap
namespace :deploy do</p>

<p>  desc &ldquo;Makes sure local git is in sync with remote.&rdquo;
  task :check_revision do</p>

<pre><code>unless `git rev-parse HEAD` == `git rev-parse origin/master`
  puts "WARNING: HEAD is not the same as origin/master"
  puts "Run `git push` to sync changes."
  exit
end
</code></pre>

<p>  end</p>

<p>  %w[start stop restart].each do |command|</p>

<pre><code>desc "#{command} Unicorn server."
task command do
  on roles(:app) do
    execute "/etc/init.d/unicorn_#{fetch(:application)} #{command}"
  end
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>The <code>check_revision</code> task checks to make sure we pushed all our local changes to the remote master branch; if it finds that our local code is out of sync with the remote, the <code>exit</code> statement will cause Capistrano to quit. We&rsquo;ll want to run this task <em>before</em> Capistrano runs its own <code>deploy</code> task to make sure we don’t forget to push our local changes up to GitHub when trying to deploy.</p>

<p>The second block of code actually creates <em>three</em> separate tasks that will allow us to start, stop, and restart Unicorn from our local computer. We&rsquo;ll run the <code>restart</code> task, for example, after Capistrano finishes its deploy so Unicorn picks up the new code. (Note that I created a namespace called <code>deploy</code> to contain these tasks since that&rsquo;s what they&rsquo;re related to.)</p>

<p>But how do we tell Capistrano to run these tasks as part of its deploy? Well, Capistrano provides two callback functions called <code>before()</code> and <code>after()</code> to help us out, and the code below illustrates how it&rsquo;s done (add it to the end of your <code>deploy.rb</code> file):</p>

<p>``` ruby deploy.rb
&hellip;</p>

<p>namespace :deploy do
  before :deploy, &ldquo;deploy:check_revision&rdquo;
  after :deploy, &ldquo;deploy:restart&rdquo;
  after :rollback, &ldquo;deploy:restart&rdquo;
end
```</p>

<p>We&rsquo;re first using <code>before()</code> to tell Capistrano to run our <code>check_revision</code> task before it runs its own <code>deploy</code> task. Then we use <code>after()</code> to make sure Capistrano restarts Unicorn after a <code>deploy</code>. Finally, we do the same thing after a <code>rollback</code> task, which is a task that simply allows you to rollback to the previous deploy if you don&rsquo;t like the current one, for whatever reason, and it&rsquo;s invoked by running <code>cap production deploy:rollback</code>. Of course, we could use these callbacks with <em>any</em> task to run <em>any other</em> task, and this is powerful because it allows us to reuse and extend our code in different ways.</p>

<p>I&rsquo;d like to point out that we&rsquo;re using the callbacks inside a namespace to make sure Capistrano knows which tasks the callbacks are referencing. This way Capistrano will know to run the <code>deploy</code> task, for example, that&rsquo;s defined in its own <code>deploy</code> namespace, and not some other task with an identical name defined somewhere else.</p>

<p>What we now have is our own custom recipe (a Capistrano term meaning a series of tasks) for deployment. You can similarly write multiple other recipes to help you automate any other tedious work you find yourself doing over and over again.</p>

<p>Alright, having all the necessary tasks defined, we can go ahead and push our code up to GitHub so Capistrano can deploy the latest changes:</p>

<p><code>bash
git add .
git commit -m "message"
git push origin master
</code></p>

<p>We’re now ready to deploy.</p>

<h1>Show Time</h1>

<p>This is a moment that was a long time coming. Let’s see what happens:</p>

<p><code>bash
cap production deploy
</code></p>

<p>It&rsquo;s likely that you encountered some type of error before the task was able to finish. This is normal&mdash;something always goes wrong the first time you deploy (if everything went smoothly, on the other hand, you deserve a place in the Capistrano hall of fame). Capistrano configurations are specific to your setup/environment, and what worked for me may not necessarily work for you. The best advice I can give is to google the specific problem you’re having, and it’s likely you&rsquo;ll find someone who struggled with the same thing and already provided a possible solution for you.</p>

<h2>Breaking It Down</h2>

<p>A lot of things happened when we ran <code>cap production deploy</code>. If you do an <code>ls</code> on your <code>deploy_to</code> directory, for example, you’ll find four new directories there:</p>

<ul>
<li><code>/releases</code>: whenever you deploy, a new directory will be created here containing all the code for that deploy</li>
<li><code>/current</code>: a symlink pointing to the latest directory in <code>/releases</code></li>
<li><code>/shared</code>: holds files and directories that persist throughout deploys</li>
<li><code>/repo</code>: contains a clone of your <code>.git</code> repo</li>
</ul>


<p>With regards to the directories in <code>/shared</code>, the main ones you need to know about are:</p>

<ul>
<li><code>/config</code>: contains our <code>database.yml</code> file</li>
<li><code>/log</code>: contains the <code>production.log</code> and <code>unicorn.log</code> files (see <code>/var/log/nginx/error.log</code> for the Nginx log file)</li>
<li><code>/public/assets</code>: contains all your assets</li>
<li><code>/tmp/pids</code>: will contain a <code>unicorn.pid</code> file that stores the process ID of Unicorn’s master process (when it&rsquo;s running)</li>
</ul>


<p>When you run <code>cap production deploy</code>, you’re actually calling a Capistrano task called <code>deploy</code>, which then sequentially invokes other tasks. The main ones are listed below:</p>

<ol>
<li><code>starting</code>: creates the directory structure and checks that the GitHub repository is reachable</li>
<li><code>updating</code>: copies the GitHub repository to a new <code>/releases</code> directory, adds symlinks pointing to <code>/shared</code>, runs Bundler, runs migrations, and compiles assets</li>
<li><code>publishing</code>: symlinks the <code>/current</code> directory to the new <code>/releases</code> directory</li>
<li><code>finishing</code>: removes old <code>/releases</code> directories</li>
</ol>


<p>If you run <code>cap -T</code>, you’ll see all these tasks listed, along with some other tasks that Capistrano runs during a deploy (see the <a href="http://capistranorb.com/documentation/getting-started/flow/">documentation</a> to learn when they&rsquo;re run). The tasks we defined ourselves will also be listed there, along with their descriptions.</p>

<p>Now that our code is deployed, we can run the two other tasks in <code>deploy.rb</code>. If you have a seed file for seeding your database, you can run <code>cap production setup:seed_db</code> to invoke it; otherwise, you&rsquo;ll need to run <code>cap production setup:symlink_config</code> to symlink your config files.</p>

<h1>Wrapping Up</h1>

<p>One last thing we have left to do is add our symlinked Unicorn script (the one in <code>/etc/init.d</code>) to Ubunut’s startup scripts to make sure Unicorn will automatically start up whenever we restart our VPS. We can do this easily using the <code>update-rc.d</code> utility; we just need to give it a name of a file in <code>/etc/init.d</code>, and it&rsquo;ll automatically add it to the correct startup folders. Below is the command that does this (be sure to change <code>unicorn_phindee</code> to the name of your own script):</p>

<p><code>bash
sudo update-rc.d unicorn_phindee defaults
</code></p>

<p>This was already done automatically, by the way, for Nginx and PostgreSQL when we installed them with <code>apt-get</code> in part 2, which means that whenever we restart our VPS, these services will be restarted automatically as well.</p>

<p>Once that’s done, I’ll log in to my VPS and restart Nginx (so it picks up the <code>nginx.conf</code> file we symlinked). Then I’ll start Unicorn by calling <code>start</code> on the <code>unicorn_phindee</code> script (be sure to use your own file name):</p>

<p><code>bash
sudo service nginx restart
/etc/init.d/unicorn_phindee start
</code></p>

<p>If you now open up your favorite browser (I hope it&rsquo;s not Internet Explorer) and type your server’s IP address into the address bar, you might see your app; if you you don&rsquo;t, don&rsquo;t worry. Deployment is hard and takes a while to sink in. If things aren’t working, your best bet is to start with the logs and google any errors you find there.</p>

<p>But the most important thing is to not get discouraged. When I set up my production server from scratch for the very first time, it took me a <em>full week</em> (I’m not kidding) to get it working. It was frustrating, discouraging, and is the reason why I decided to write this series, because I didn’t want other people going through the same thing. It doesn&rsquo;t have be that way though, and I hope it won&rsquo;t be.</p>

<p>Stay hungry. Stay foolish.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 5: Configuring Capistrano]]></title>
    <link href="http://vladigleba.github.io/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/"/>
    <updated>2014-04-04T07:36:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano</id>
    <content type="html"><![CDATA[<p>In the previous four posts, I covered how I went about setting up my server for Phindee and how I configured Unicorn and Nginx. Here in part 5, I will now talk about how I configured Capistrano to actually deploy Phindee.</p>

<!-- more -->


<p>If you’re not familiar with it, <a href="http://capistranorb.com/">Capistrano</a> is the de-facto deployment tool for Rails apps; it makes deployment easier by automating a lot of the work for you, and it can be easily customized to suit your particular needs. If you’ve never used it before, I hope this post will give you a taste of what it can do.</p>

<p>By the way, I’ll be using version 3, which came out last summer; it’s a complete rewrite that ended up reducing Capistrano’s footprint to just 700 lines of code! If you’re coming from version 2, I recommend reading <a href="https://semaphoreapp.com/blog/2013/11/26/capistrano-3-upgrade-guide.html">this post</a> to learn about the differences.</p>

<p>One of the ways the core team was able to keep it so lean was by breaking framework-specific tasks into separate gems, which means that in addition to installing the Capistrano gem itself, we’ll need to install Rails-specific gems as well. Here is what you should add to your <code>Gemfile</code>:</p>

<p>``` ruby Gemfile
&hellip;</p>

<p>group :development do
  gem &lsquo;capistrano&rsquo;, &lsquo;~> 3.1.0&rsquo;
  gem &lsquo;capistrano-rails&rsquo;, &lsquo;~> 1.1.1&rsquo;
  gem &lsquo;capistrano-bundler&rsquo;, &lsquo;~> 1.1.1&rsquo;
  gem &lsquo;capistrano-rbenv&rsquo;, &lsquo;~> 2.0.2&rsquo;
end
```</p>

<p>Since we’ll only be using Capistrano in development, we put all the gems in the <code>:development</code> group. Note that we added Rails-specific tasks through the <code>capistrano-rails</code> gem, Bundler-specific tasks through the <code>capistrano-bundler</code> gem, and rbenv-specific tasks through the <code>capistrano-rbenv</code> gem.</p>

<p>We can install them by running <code>bundle</code> in the root directory of our Rails app. After Bundler finishes the install, we’ll tell Capistrano to create the necessary files it needs to do its job by running the following:</p>

<p><code>bash
cap install
</code></p>

<p>One of the files this created is called <code>Capfile</code>, which will be located in the root directory of your Rails app. It&rsquo;ll contain various <code>require</code> statements to load the necessary code that Capistrano will need to do its job. We’ll open it up and uncomment the following lines to load the gems we just installed:</p>

<p><code>ruby Capfile
require 'capistrano/rails'
require 'capistrano/bundler'
require 'capistrano/rbenv'
</code></p>

<p>You’ll also see the following line at the end of the file:</p>

<p><code>ruby Capfile
Dir.glob('lib/capistrano/tasks/*.cap').each { |r| import r }
</code></p>

<p>This will load any custom tasks from <code>lib/capistrano/tasks</code>, which we will later define.</p>

<h1>Roll up Your Sleeves</h1>

<p>One cool thing about Capistrano is it’s designed to work with different deployment scenarios. You could, for example, have both a production server running your “live” application and a staging server meant for testing newly developed features before they’re pushed to the production server. In other words, you’d have two deployment stages: production and staging. When we ran <code>cap install</code>, Capistrano actually already created the necessary files for this; they’re located inside the <code>/config/deploy</code> directory and are named <code>production.rb</code> and <code>staging.rb</code>, respectively. We’ll use them to define stage-specific configurations, while configurations that are meant to be shared across all stages will be set in <code>config/deploy.rb</code>, and that’s where we’ll start first.</p>

<h2>General Configuration</h2>

<p>Below is how my <code>deploy.rb</code> file looks like for Phindee:</p>

<p>``` ruby deploy.rb
lock &ldquo;3.1.0&rdquo;</p>

<p>set :application, &ldquo;phindee&rdquo;
set :repo_url, &ldquo;git@github.com:vladigleba/phindee.git&rdquo;</p>

<p>set :deploy_to, &ldquo;/var/www/#{fetch(:application}&rdquo;
set :deploy_user, &ldquo;bob&rdquo;</p>

<p>set :rbenv_type, :user # or :system, depends on your rbenv setup
set :rbenv_ruby, &ldquo;2.1.0&rdquo;
set :rbenv_prefix, &ldquo;RBENV_ROOT=#{fetch(:rbenv_path)} RBENV_VERSION=#{fetch(:rbenv_ruby)} #{fetch(:rbenv_path)}/bin/rbenv exec&rdquo;
set :rbenv_map_bins, %w{rake gem bundle ruby rails}
set :rbenv_roles, :all # default value</p>

<p>set :linked_files, %w{config/database.yml}
set :linked_dirs, %w{bin log tmp/pids tmp/cache tmp/sockets vendor/bundle public/system}</p>

<p>set :keep_releases, 5
```</p>

<p>The very first line locks the configurations in this file to Capistrano 3.1, and if you have any other version installed, the file won’t run. (This is designed to help prevent configurations from braking between version updates.)</p>

<p>Next, we’re using the <code>set()</code> function to initialize the <code>:application</code> variable to “phindee.” (We’ll retrieve this variable’s value later using the corresponding <code>fetch()</code> function.) We’re also setting the <code>:repo_url</code> variable to the URL of the GitHub repository containing your code so Capistrano  knows where to look when we deploy. By the way, if your code is on a branch other than “master,” you’ll need to specify its name by adding <code>set :branch, “branch-name”</code>; otherwise, this is not needed because Capistrano sets it to “master” by default.</p>

<p>The next line sets the <code>:deploy_to</code> variable to the path where you want Capistrano storing the code it downloads from GitHub. This should be the same path you previously set in <code>unicorn.rb</code>, but without the <code>/current</code> directory appended to it. This is because <code>/current</code> represents the directory with the latest deploy code, while Capistrano is interested in the general app directory.</p>

<p><code>:deploy_user</code> is then set to the user Capistrano will be deploying as, and this should match the user you created when you setup your server in <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>.</p>

<p>The next few lines set variables needed by rbenv, and I actually copied and pasted these lines from the <code>capistrano-rbenv</code> <a href="https://github.com/capistrano/rbenv">README file</a>. The key variable here is <code>:rbenv_ruby</code>, which sets the Ruby version that rbenv installed on your machine, and you can run <code>ls ~/.rbenv/versions</code> in the command line to find which version that is. If this is not set correctly, the deploy will fail.</p>

<p>The other variable worth mentioning here is <code>:rbenv_type</code>. We could set it to <code>:system</code> if rbenv was installed system-wide on our machine, but since we installed rbenv on a per-user basis inside <code>~/.rbenv</code>, we&rsquo;re setting it to <code>:user</code>. System-wide installs can lead to problems with permissions, and it’s generally cleaner to just do a per-user install. The other three variables don’t need to be modified, and you can leave them the way they are.</p>

<p>Moving on, we’re setting the <code>:linked_files</code> variable to an array of strings initialized to <code>config/database.yml</code>. This tells Capistrano to store our app’s <code>config/database.yml</code> file inside a directory called <code>/shared</code>, which is meant for any files we want to persist between deploys. Since the contents of <code>database.yml</code> won’t change between deploys, it’s a good idea to store it there.</p>

<p>Similarly, <code>:linked_dirs</code> contains <em>directories</em> that are meant to persist between deploys, and they too will be stored inside <code>/shared</code>. These include directories containing things like log files, Unicorn sockets, and <code>.pid</code> files that will all stay the same between deploys.</p>

<p>And finally, <code>:keep_releases</code> tells Capistrano to only keep the last 5 deploys and discard everything else. This can be useful whenever you need to rollback to a previous release, but you also don&rsquo;t want releases piling up, so it&rsquo;s best not to set this number too high.</p>

<h2>Stage-Specific Configuration</h2>

<p>Now that <code>deploy.rb</code> is configured, we’ll move on to defining stage-specific configurations. Since I currently don’t have a separate environment for staging, I’ll only be going over the <code>config/deploy/production.rb</code> file, and you can just leave <code>staging.rb</code> the way it is by default. Below is how my <code>production.rb</code> file looks like:</p>

<p>``` ruby production.rb
set :stage, :production
set :rails_env, :production</p>

<p>server &lsquo;xxx.xxx.xxx.xxx&rsquo;, user: &lsquo;bob&rsquo;, port: 12345, roles: %w{web app db}, primary: true
```</p>

<p>As you can see, there isn’t much going on here. We’re first setting the <code>:stage</code> variable to <code>:production</code> to let Capistrano know that this file is meant for production. We’re also setting the <code>:rails_env</code> variable to the same thing to make sure Rails runs in the production environment. But the key line is the last line, which tells Capistrano how to access our VPS server. Make sure you replace the Xs with the IP address of the server you setup in part 1, along with the user and port number it&rsquo;s set up with.</p>

<p>We’re then using the <code>:roles</code> variable to let Capistrano know that our database server (PostgreSQL) represented by <code>db</code>, web server (Nginx) represented by <code>web</code>, and application server (Unicorn) represented by <code>app</code> all run on the same machine. Apps with lots of traffic, on the other hand, might have multiple separate physical servers for each of these. Setting <code>:primary</code> to <code>true</code> then tells Capistrano that this is our primary database server, and Capistrano will run migrations only on the one we designate as <code>:primary</code>. Even if we’re running all our servers on the same physical machine, setting <code>:primary</code> is still necessary.</p>

<h1>Enabling Agent Forwarding</h1>

<p>Now that Capistrano knows how to access our VPS, we need to make sure it can also access our code on GitHub. We’ll be using agent forwarding to allow us to reuse the local key we generated in part 1 to authenticate with GitHub. In order for this to work, we’ll need to add the key to GitHub, and you can do so by following step 3 on <a href="https://help.github.com/articles/generating-ssh-keys#step-3-add-your-ssh-key-to-github">this GitHub page</a>.</p>

<p>To enable agent forwarding in Capistrano 2, you had explicitly set it in <code>deploy.rb</code>, but in Capistrano 3, it’s already taken care of and enabled by default. The only thing we have left to do is log in to our VPS and run the following command to add github.com to the list of known hosts; this ensures Capistrano won’t have any problems with it being unknown when it tries downloading your code from GitHub to your server:</p>

<p><code>bash
ssh git@github.com
</code></p>

<p>You’ll get a warning asking if you’re sure you want to continue connecting. Verify that the key fingerprint matches the one you just added to GitHub, and enter “yes”. If you get an “access denied” message, see <a href="https://help.github.com/articles/error-permission-denied-publickey">this page</a> for potential solutions. If you’re experiencing some other agent forwarding problems, <a href="https://help.github.com/articles/using-ssh-agent-forwarding#troubleshooting">this page</a> might help you out.</p>

<h1>Setting Permissions</h1>

<p>If you look at <code>deploy.rb</code>, you’ll notice I set the <code>:deploy_to</code> variable to “/var/www/phindee,” but on my VPS, the <code>/var</code> directory doesn’t yet contain the <code>/www</code> directory. That’s not a problem since Capistrano will create it for me through the user <code>bob</code>, as specified in <code>deploy.rb</code>, but it needs write permissions to do so.</p>

<p>If you read <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>, you’ll remember we created a group called <code>deployers</code> to contain users with deployment privileges and added the user <code>bob</code> into it. This means we can give the necessary permissions <code>bob</code> will need by simply giving them to <code>deployers</code>, and since <code>bob</code> is a member of the group, he will automatically inherit them.</p>

<p>I’m already logged in to my VPS as <code>bob</code>, and I can change the <code>/var</code> directory’s group to <code>deployers</code> with the following command:</p>

<p><code>bash
sudo chgrp deployers /var
</code></p>

<p>We can then give this group write permissions so its members can create directories within <code>/var</code>:</p>

<p><code>bash
sudo chmod g+w /var
</code></p>

<p>There are two other places where we need to repeat this process. The first is the <code>/etc/nginx/sites-enabled</code> directory, which Nginx uses to store its configuration files, and this is where our <code>config/nginx.conf</code> file that we created in <a href="/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/">part 4</a> will go. But we actually won’t be storing the file itself there; we’ll create a symlink to it, instead. This will make our deploys easier to manage because we won’t need to add our <code>nginx.conf</code> file to the <code>/etc/nginx/sites-enabled</code> directory <em>every</em> time we deploy. We can simply symlink it since Capistrano will always store our latest deploy code in the same place (<code>/var/www/phindee/current</code>).</p>

<p>Same thing is needed for the <code>config/unicorn_init.sh</code> file from <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>. We’ll need to create a symlink inside <code>/etc/init.d</code>, since that’s the directory Linux uses to store all the shell scripts used to manage the various services installed on the system. When we installed Nginx in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, for example, a shell script was automatically installed there to help us manage Nginx, and it will be invoked whenever we run a command like <code>sudo service nginx restart</code>. There is nothing like this for Unicorn yet, which is why we need to create a symlink to our <code>unicorn_init.sh</code> script to give us similar functionality.</p>

<p>In order for Capistrano to create symlinks, it needs write permissions in the relevant directories. We can give them with the following commands:</p>

<p>``` bash
sudo chgrp deployers /etc/nginx/sites-enabled
sudo chmod g+w /etc/nginx/sites-enabled</p>

<p>sudo chgrp deployers /etc/init.d
sudo chmod g+w /etc/init.d
```</p>

<p>And now Capistrano should have the necessary permissions to do its work.</p>

<p>Having Capistrano configured, we’re ready to move on and start writing custom tasks to help us deploy our code, and that’s exactly what we’ll do in the <a href="/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks/">next and last post</a> of this series. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you&rsquo;ll get it delivered to your inbox as soon as it’s released.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 4: Configuring Nginx]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/"/>
    <updated>2014-03-27T12:50:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx</id>
    <content type="html"><![CDATA[<p>I talked about how I configured Unicorn for <a href="http://phindee.com/">Phindee</a> in <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>, and now I&rsquo;ll cover how I configured Nginx. While Unicorn will handle requests for pages dynamically generated by Rails, Nginx will handle requests for static assets, like stylesheets, scripts, images, and fonts. If you’re wondering why I chose Nginx over Apache, see <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a> for the explanation.</p>

<!-- more -->


<p>Alright, since there is quite a bit to cover, we’ll jump right in. We’ll start by creating a file called <code>nginx.conf</code> inside our app’s <code>/config</code> directory on our local computer. Here’s how mine looks like:</p>

<p>``` nginx nginx.conf
upstream unicorn {
  server unix:/tmp/unicorn.phindee.sock fail_timeout=0;
}</p>

<p>server {
  server_name www.phindee.com;
  return 301 $scheme://phindee.com$request_uri;
}</p>

<p>server {
  listen 80 default deferred;
  server_name phindee.com;
  root /var/www/phindee/current/public;</p>

<p> location ^~ /assets/ {</p>

<pre><code>gzip_static on;
expires max;
add_header Cache-Control public;
</code></pre>

<p>  }</p>

<p>  try_files $uri/index.html $uri @unicorn;
  location @unicorn {</p>

<pre><code>proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header Host $http_host;
proxy_redirect off;
proxy_pass http://unicorn;
</code></pre>

<p>  }</p>

<p>  error_page 500 502 503 504 /500.html;
  keepalive_timeout 10;
}
```</p>

<p>You might have noticed that the first thing we do is specify the number of workers to run. If you read part 3, this will sound familiar, because Nginx, just like Unicorn, has a master process managing all the workers, and the workers are the ones responsible for processing requests from clients. Unlike Unicorn, Nginx also has a cache loader process that checks and/or populates the cache with metadata, as well a cache manager process that’s responsible for cache expiration. Together, they keep Nginx internals running quickly and efficiently.</p>

<h1>A Bit on Workers</h1>

<p>If you log in to your VPS and <code>cd</code> into <code>/etc/nginx</code>, you&rsquo;ll find a file called <code>nginx.conf</code>. This is the main Nginx configuration file that Nginx will parse when it runs, and it&rsquo;s the place where you can modify the number of workers available to process requests. You can do this by modifying the <code>worker_processes</code> directive defined at the top of the file. It&rsquo;s set to four workers by default, but I changed mine to one because that&rsquo;s more than enough for a low-traffic app. It&rsquo;s also possible to modify the number of connections a worker can accept by modifying the <code>worker_connections</code> directive inside the <code>events</code> block; I changed mine to 1024 connections.</p>

<p>This means that given our current configuration, our server will be able to accept a total of 1024 simultaneous connections. If you want to increase this, it’s generally best to increase the <code>worker_connections</code> value before increasing the number of workers. (Remember, each worker is a single-threaded process, so whenever you increase the number of workers, you’re also increasing the total amount of memory that will be used.) But having one worker process that’s capable of handling 1024 connections is more than enough for a low-traffic app.</p>

<p>By the way, if you&rsquo;re wondering how our own <code>nginx.conf</code> file we created above will get executed, <code>/etc/nginx/nginx.conf</code> already has an <code>include</code> directive inside the <code>http</code> block that will automatically include any files in the <code>/etc/nginx/sites-enabled</code> directory, and that&rsquo;s the place where we will put our own <code>nginx.conf</code> file when it&rsquo;s time to deploy.</p>

<h1>Hooking up with Unicorn and Handling Redirects</h1>

<p>Since Nginx is not capable of handling requests for pages that are dynamically generated by Rails, we need to tell it to somehow pass such requests off to Unicorn. We’ll take the first step to accomplishing this by defining an <code>upstream</code> block called <code>unicorn</code>, inside which we point the server to the same Unix socket that we used in our <code>unicorn.rb</code> file from <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>. This is just the first step, however, and more work needs to be done to get this working, as you’ll see later. By the way, in case you’re wondering, setting <code>fail_timeout</code> to 0 is necessary for Nginx to correctly handle Unicorn timing out due to its worker being killed when it takes longer than 30 seconds to respond, as specified in <code>unicorn.rb</code>.</p>

<p>The <code>server</code> block right below the <code>upstream</code> block is there to redirect a request for &ldquo;www.phindee.com&rdquo; to &ldquo;phindee.com&rdquo;. The <code>server_name</code> directive specifies the URL we’re redirecting from, while the <code>return</code> directive specifies where to redirect to. (Notice we’re returning a 301 status code to specify a permanent redirection.) The <code>$scheme</code> variable stores the HTTP scheme (i.e. http, https), while <code>$request_uri</code> stores the unmodified URI of a client request, which includes the arguments, but not the host name (e.g. &ldquo;/foo/bar.php?arg=baz&rdquo;).</p>

<h1>Where the Meat Is</h1>

<p>The next <code>server</code> block contains the main configuration. The <code>listen</code> directive inside it tells Nginx to listen on port 80, and the <code>server_name</code> directive right below specifies the domain name that Nginx will try to match, which is &ldquo;phindee.com&rdquo; in my case.</p>

<p>Specifying <code>default</code> in the <code>listen</code> directive, by the way, tells Nginx to use this server block by default if it can’t find a matching domain name, which means I could technically leave out the <code>server_name</code> directive completely, and everything would still work because of <code>default</code>, but I like to leave it in for readability. And finally, I added the <code>deferred</code> option since I’m running this on Linux, which tells Nginx to use the <code>TCP_DEFER_ACCEPT</code> option to <a href="http://www.techrepublic.com/article/take-advantage-of-tcp-ip-options-to-optimize-data-transmission/">speed up performance</a> by reducing the amount of preliminary work that happens between a client and the server.</p>

<p>Moving along, the <code>root</code> directive specifies the directory in which Nginx will look to handle requests for static files. This is basically the directory we specified inside <code>unicorn.rb</code>, except it has an additional <code>/public</code> directory appended to the end of it. It corresponds to your app’s <code>/public</code> directory on your local computer and is the place where your static files are and will reside. Currently, it only contains various error pages, a favicon, and a <code>robots.txt</code> file for search engines. When we later deploy with Capistrano, it’ll contain all our assets as well, including stylesheets, scripts, images, and fonts.</p>

<h1>Handling Asset Requests</h1>

<p>Just like the <code>server_name</code> directive handles requests for domain names, the <code>location</code> directive handles requests for specific files and folders. The caret and tilde (^~) tells Nginx to do a regular expression match on <code>/assets/</code> and to stop searching as soon as it finds a match (see the <a href="https://library.linode.com/web-servers/nginx/configuration/basic#sph_location-file-and-folder-configuration">Linode Guide</a> to learn more).</p>

<p>By setting the <code>gzip_static</code> directive to <code>on</code>, we’re then telling Nginx to look for an already pre-compressed <code>.gz</code> file <em>before</em> proceeding to compress it. This prevents Nginx from compressing the same file each time it is requested.</p>

<p>The <code>expires</code> directive then makes the response cacheable and marks it with an expiry date set to <code>max</code>, which is equivalent to December 31st, 2037. This tells browsers and any caching servers to not request these assets again until the specified date. Of course, if we make changes to our stylesheets, for example, Rails will change the filename and browsers will still receive the latest version, which will then also be cached.</p>

<p>Using the <code>expires</code> directive, however, is an outdated method of specifying caching, and it’s recommended to use <code>Cache-Control</code> header instead. The next line in the code does just that through the <code>add_header</code> directive. (The reason we include  <code>expires</code> is to make things backward-compatible.) It’s possible, by the way, to set <code>Cache-Control</code> to either <code>public</code> or <code>private</code>, and I’m setting it to <code>public</code> because we’re caching assets that are meant to be used by everybody, whereas <code>private</code> would mean they’re unique to individual users (see <a href="http://stackoverflow.com/questions/3492319/private-vs-public-in-cache-control">Stack Overflow</a> to learn more).</p>

<h1>Trying to Find a Match</h1>

<p>The next line is the <code>try_files</code> directive, which is there for requests that didn’t match with any <code>location</code> blocks. In our case, it tries to match non-asset requests. The <code>$uri</code> variable inside it contains the current request URI, minus the arguments, protocol, and host name, so if we typed in &ldquo;phindee.com/foobar&rdquo; into the address bar, the <code>$uri</code> would be &ldquo;/foobar&rdquo;, and given our <code>try_files</code> directive, Nginx would try to first match a <code>var/www/phindee/current/public/foobar/index.html</code> file. If it found no such file, it would then try to match the <code>/foobar</code> directory itself, and if that didn’t work, it would then pass the request off to Unicorn through a named location, which is defined next through the <code>location</code> directive and called <code>@unicorn</code>.</p>

<p>Inside the named location, the <code>proxy_pass</code> directive does all the heavy lifting. We set it to <code>http://unicorn</code> so that it points to the <code>upstream</code> block called <code>unicorn</code>, which we already defined, and the request is then handled by the Unicorn socket defined there. The two <code>proxy_set_header</code> directives then append additional headers needed for Unicorn, while <code>proxy_redirect</code> set to <code>off</code> prevents Nginx from doing any redirect handling. (There is a sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file on GitHub</a> with comments explaining why this is necessary.)</p>

<h1>Last Few Lines</h1>

<p>Alright, we’re down to the last two lines. <code>error_page</code> makes sure that our app’s <code>500.html</code> page is shown for any 500-related errors, while <code>keepalive_timeout</code> tells Nginx to retain keep-alive connections (also known as persistent connections) for up to 10 seconds and close them if they exceed that time. The main concern when choosing the amount of time is mobile devices on slow networks, but I think 10 seconds should be enough.</p>

<p>Keep-alive connections, by the way, send multiple HTTP requests in a single connection, as opposed to opening a new connection for each request; in HTTP 1.1, all connections are persistent by default, which means stylesheets, scripts, images, and fonts, for example, would all be sent using a single connection.</p>

<p>These are, of course, not all the options you can specify. If you’d like to learn about the additional ones, feel free to read through the comments in the sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file</a> I mentioned earlier.</p>

<p>And that wraps up part 4. I will introduce Capistrano in the <a href="/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/">next post</a> and will explain how I configured it for Phindee. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you&rsquo;ll get it delivered to your inbox as soon as it’s released.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 3: Configuring Unicorn]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/"/>
    <updated>2014-03-21T10:08:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn</id>
    <content type="html"><![CDATA[<p>Having covered how to install the technology stack powering Phindee in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, I will now shift gears and talk about how I configured Unicorn. I already explained why I chose to install Nginx, but I haven’t yet explained why I chose Unicorn, so here we go.</p>

<!-- more -->


<p><a href="http://unicorn.bogomips.org/">Unicorn</a> is an HTTP server for Ruby. It&rsquo;s designed to be used in a production environment, unlike WEBrick, which is designed for running your app on your local computer. Because it&rsquo;s fast, efficient, and offers tons of cool features, like load balancing and rolling restarts, Unicorn has become a popular production server for Rails apps.</p>

<h1>Comparing Unicorn with Passenger</h1>

<p>When I deployed Phindee for the first time, however, I actually used the open source version of <a href="https://www.phusionpassenger.com/">Phusion Passenger</a>, due to the fact that it was (and is) easier to setup than Unicorn. My main concern, at the time, was to have a functioning app deployed as soon as possible, with as little effort as possible, and Passenger helped me do just that.</p>

<p>Eventually, I reached a point where I was ready for something that I could configure myself, and Unicorn seemed like a good next step. But if you’re a beginner, Passenger will be the easiest to start with since it’s designed to integrate into Nginx directly and, therefore, requires less work to setup and maintain. You will have to pay for the Enterprise version, however, if you want advanced features like error-resistant, zero-downtime deploys, which come for free with Unicorn.</p>

<h2>Do One Thing, Do It Well</h2>

<p>The reason why I like Unicorn is due to its philosophy of doing a few things well. An example of this is load balancing, which Unicorn hands off to the operating system entirely. When Unicorn starts, its master process spawns (forks) a configured number of processes called workers. These workers then handle the incoming requests to your app and only accept a request when they’re ready.</p>

<p>But it’s the operating system that handles the forking, as well as the distribution of requests between processes that are ready to accept, not Unicorn. What Unicorn does is the actual monitoring of workers themselves through the master process. If a worker, for example, takes too much time to complete a task, the master process will kill it and spawn a new one.</p>

<h2>Deploys Done Right</h2>

<p>What this design can achieve is error-resistant, zero-downtime deploys. Error-resistant deploys ensure that if something goes wrong during a deploy, your app will remain online and serve incoming requests using the old code. This is possible because Unicorn doesn’t kill off old workers until new workers have successfully forked, which means your old workers will stay alive if something goes wrong with the new ones.</p>

<p>Zero-downtime deploys work in a similar manner. We can send a signal to the master process telling it to start a new master, and this new master will then begin reloading our new code. Once it’s fully loaded, the new master will fork its workers. The first worker forked will notice there is still an old master running, and it’ll send a signal telling it to start gracefully shutting down its workers. When all workers finish serving their current requests, the old master then dies, and our app is fully reloaded with new code.</p>

<p>Passenger supports rolling restarts like this as well, but they only come with the paid Passenger Enterprise version. One advantage the Enterprise version provides, however, is it restarts the processes one-by-one, which requires less memory. Rolling restarts with Unicorn, on the other hand, are done all at once and temporarily require twice the memory usage. It is possible, of course, to script one-by-one rolling restarts in Unicorn, but Passenger does this automatically for you.</p>

<h1>How about Puma?</h1>

<p>Another alternative to Unicorn and Passenger is Puma. Whereas Unicorn and Passenger achieve concurrency through the use of forks, Puma achieves it by running multiple threads in a single process. Of course, this means that your code must be thread-safe, but since Rails 4 is thread-safe by default, this shouldn’t be an issue.</p>

<p>Because threading requires less memory than forking, Puma will be more memory efficient than a similar Unicorn setup. Puma, however, does not do rolling restarts, nor does watch for and restart failed processes, like Unicorn, which means you’ll need a service like <a href="http://mmonit.com/monit/">Monit</a> that monitors and restarts them for you. As with any technology, pick whatever best meets your needs.</p>

<h1>Installing and Configuring Unicorn</h1>

<p>With that out of the way, we’re now ready to start working with Unicorn. We’ll begin by adding the following line to our app’s <code>Gemfile</code> on our local computer:</p>

<p><code>ruby Gemfile
gem 'unicorn', '~&gt; 4.8.0’
</code></p>

<p>Make sure you change the version number to whatever’s the most recent one at the time of your install. The <code>~&gt;</code> notation means that any future minor updates (e.g., from 4.0.0 to 4.0.1) will be installed, but major ones (e.g., from 4.0 to 4.1) won’t be. Major updates can sometimes introduce unexpected behavior in your app, so it’s best to limit the updates to minor releases only.</p>

<p>We&rsquo;ll then install Unicorn by running <code>bundle</code> in the root path of our app, and Bundler, which we installed in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, will take care of the install for us.</p>

<p>Having Unicorn installed, we can begin configuring it. We’ll start by creating a file called <code>unicorn.rb</code> on our local computer inside the <code>/config</code> directory of our Rails application. This is how my file for Phindee looks:</p>

<p>``` ruby unicorn.rb
root = &ldquo;/var/www/phindee/current&rdquo;
working_directory root
pid &ldquo;#{root}/tmp/pids/unicorn.pid&rdquo;
stderr_path &ldquo;#{root}/log/unicorn.log&rdquo;
stdout_path &ldquo;#{root}/log/unicorn.log&rdquo;</p>

<p>listen &ldquo;/tmp/unicorn.phindee.sock&rdquo;
worker_processes 2
timeout 30
```</p>

<p>The first variable <code>root</code> represents the path to the root directory of our app, which I&rsquo;ve set to <code>/var/www/phindee/current</code>. Generally, web apps are stored inside <code>/var/www</code> on Unix since the <code>/var</code> directory is designated for files that increase in size over time, which is the case with most web apps, and a <code>/www</code> directory is typically created inside <code>/var</code> to store files meant for the web. I then have a <code>/phindee</code> directory specified inside <code>/www</code> to store all things related to Phindee, as well as a <code>current</code> directory, which Capistrano will later create and use to store the latest deployment code. You don&rsquo;t have to actually create these directories now, as Capistrano we&rsquo;ll create them itself when it runs.</p>

<p>Below is what the rest of the configurations mean:</p>

<ul>
<li><p><code>working_directory</code> specifies exactly what is says&mdash;the app’s working directory&mdash; and it’s set to the variable <code>root</code>, which we just defined.</p></li>
<li><p><code>pid</code> specifies the path to a <code>.pid</code> file that will store the process ID of Unicorn’s master process, which can be later used to stop the process itself. These files are typically stored inside the <code>/tmp</code> directory since they exist only while Unicorn is running, so you can leave this line the way it is.</p></li>
<li><p><code>stderr_path</code> and <code>stdout_path</code> specify the path to <code>stderr</code> and <code>stdout</code>. If you’re not familiar with what they mean, when a Unix program starts up, it has three streams opened for it: one for input called “standard input” (abbreviated <code>stdin</code>), one for output called “standard output” (abbreviated <code>stdout</code>), and one for printing error messages called “standard error” (abbreviated <code>stderr</code>). Given our configuration, this means that any error messages written by our Rails app to the <code>stderr</code> stream will get written to the <code>.log</code> file specified in the <code>stderr_path</code>. It’s common to point <code>stdout_path</code> to the same location as <code>stderr_path</code> and store them both inside the <code>/log</code> directory.</p></li>
<li><p><code>listen</code> specifies the path to a socket that will listen for a client wanting to make a connection request. If you’re unfamiliar with this, a socket is basically a software object consisting of a port number that’s attached to an IP address. It allows clients and servers to communicate with one another by writing to and reading from their sockets. Since they’re running only when Unicorn is running, they’re usually stored inside the <code>/tmp</code> directory as well.</p></li>
<li><p><code>worker_processes</code> specifies the number of workers that the master process will fork for client request handling. The more workers you set, the more memory you’ll need, and since I don’t have a large amount of memory on my VPS, I decided to set mine to two. This should be enough for a low-traffic app, but once your traffic rises, the number of workers, as well as the amount of memory available to your server, will need to rise with it.</p></li>
<li><p><code>timeout</code> specifies the maximum number of seconds a worker can take to respond to a request before the master kills it and forks a new one. 30 seconds is a good value to put here since whenever a worker takes longer than this to respond, it’s usually safe to assume there is something wrong with the worker itself.</p></li>
</ul>


<p>You can get a complete list of all the other possible configuration options by taking a look Unicorn’s <a href="http://unicorn.bogomips.org/Unicorn/Configurator.html">Configurator Module</a>.</p>

<h1>Managing Unicorn Processes</h1>

<p>Having Unicorn configured, we’ll now need to setup a way for us to manage the Unicorn processes themselves.</p>

<p>Unicorn uses signals to communicate with its processes, and you can find a full explanation of all the available signals <a href="http://unicorn.bogomips.org/SIGNALS.html">here</a>. But sending these signals manually would be a pain. I recommend using a <a href="https://github.com/railscasts/335-deploying-to-a-vps/blob/master/blog-nginx/config/unicorn_init.sh">script on GitHub</a> to automate this process for you. Go ahead and create your own <code>unicorn_init.sh</code> file inside your app’s <code>/config</code> directory and copy/paste the script’s code into it.</p>

<p>All the variables you can change are defined at the beginning of the script. You&rsquo;ll need to set the <code>APP_ROOT</code> variable to the same path that the <code>root</code> variable in <code>unicorn.rb</code> is set to, and you&rsquo;ll want to set the <code>AS_USER</code> variable to the user you set up your server with in <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>. Lastly, you&rsquo;ll want to modify the <code>CMD</code> variable by adding <code>~/.rbenv/bin/rbenv exec</code> right after <code>cd $APP_ROOT;</code>, but right before <code>bundle exec unicorn ...</code>, which is necessary so that the correct environment variables are set when we run the command remotely through Capistrano.</p>

<p>If you’re inside the root directory of your Rails app, you can then make the script executable with the following command:</p>

<p><code>bash
chmod +x config/unicorn_init.sh
</code></p>

<p>I’d like to point out that the way <code>unicorn.rb</code> and <code>unicorn_init.sh</code> is currently setup, Unicorn won’t be doing rolling restarts. If you look at <code>unicorn_init.sh</code>, for example, you’ll notice that it sends a <code>HUP</code> signal when you run the script’s <code>restart</code> command. This signal doesn’t spawn a new master process, the way a rolling restart would do; it simply reloads the <code>unicorn.rb</code> file and gracefully restarts all the workers using the same master process.</p>

<p>You’d need to use the <code>USR2</code> signal for a rolling restart (which is actually what happens when you run the script’s <code>upgrade</code> command). But even then, there are still additional steps you’ll need to take to make everything runs smoothly, like making sure your database connections carry over, as well as ensuring any changes to the database are compatible with the older code.</p>

<p>I won’t be explaining how to do this here because I haven’t yet set it up myself, but if you’re curious, there is a good <a href="http://www.justinappears.com/blog/2-no-downtime-deploys-with-unicorn/">blog post</a> explaining all the nuances you need to be aware of. Phindee is currently a small, low-traffic app and its code is reloaded within seconds, so I’m not worried about users waiting for their requests and don’t see a need for rolling restarts at the moment, but I’m hoping the need presents itself soon.</p>

<p>Having configured Unicorn, we&rsquo;ll move on to configuring Nginx in <a href="/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/">part 4</a>. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and the post will be delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
</feed>
