<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Topic: Deployment | Hungry and Foolish]]></title>
  <link href="http://vladigleba.github.io/blog/topics/deployment/atom.xml" rel="self"/>
  <link href="http://vladigleba.github.io/"/>
  <updated>2014-04-07T12:05:51-07:00</updated>
  <id>http://vladigleba.github.io/</id>
  <author>
    <name><![CDATA[Vladi Gleba]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 5: Configuring Capistrano]]></title>
    <link href="http://vladigleba.github.io/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/"/>
    <updated>2014-04-04T07:36:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano</id>
    <content type="html"><![CDATA[<p>In the previous four posts, I covered how I went about setting up my server for Phindee and how I configured Unicorn and Nginx. Here in part 5, I will now talk about how I configured Capistrano to actually deploy Phindee.</p>

<!-- more -->


<p>If you’re not familiar with it, <a href="http://capistranorb.com/">Capistrano</a> is the de-facto deployment tool for Rails apps; it makes deployment easier by automating a lot of the work for you, and it can be easily customized to suit your particular needs. If you’ve never used it before, I hope this post will give you a taste of what it can do.</p>

<p>By the way, I’ll be using version 3, which came out last summer; it’s a complete rewrite that ended up reducing Capistrano’s footprint to just 700 lines of code! If you’re coming from version 2, I recommend reading <a href="https://semaphoreapp.com/blog/2013/11/26/capistrano-3-upgrade-guide.html">this post</a> to learn about the differences.</p>

<p>One of the ways the core team was able to keep it so lean was by breaking framework-specific tasks into separate gems, which means that in addition to installing the Capistrano gem itself, we’ll need to install Rails-specific gems as well. Here is what you should add to your <code>Gemfile</code>:</p>

<p>``` ruby Gemfile
&hellip;</p>

<p>group :development do
  gem &lsquo;capistrano&rsquo;, &lsquo;~> 3.1.0&rsquo;
  gem &lsquo;capistrano-rails&rsquo;, &lsquo;~> 1.1.1&rsquo;
  gem &lsquo;capistrano-bundler&rsquo;, &lsquo;~> 1.1.1&rsquo;
  gem &lsquo;capistrano-rbenv&rsquo;, &lsquo;~> 2.0.2&rsquo;
end
```</p>

<p>Since we’ll only be using Capistrano in development, we put all the gems in the <code>:development</code> group. Note that we added Rails-specific tasks through the <code>capistrano-rails</code> gem, Bundler-specific tasks through the <code>capistrano-bundler</code> gem, and rbenv-specific tasks through the <code>capistrano-rbenv</code> gem.</p>

<p>We can install them by running <code>bundle</code> in the root directory of our Rails app. After Bundler finishes the install, we’ll tell Capistrano to create the necessary files it needs to do its job by running the following:</p>

<p><code>bash
cap install
</code></p>

<p>One of the files this created is called <code>Capfile</code>, which will be located in the root directory of your Rails app. It&rsquo;ll contain various <code>require</code> statements to load the necessary code that Capistrano will need to do its job. We’ll open it up and uncomment the following lines to load the gems we just installed:</p>

<p><code>ruby Capfile
require 'capistrano/rails'
require 'capistrano/bundler'
require 'capistrano/rbenv'
</code></p>

<p>You’ll also see the following line at the end of the file:</p>

<p><code>ruby Capfile
Dir.glob('lib/capistrano/tasks/*.cap').each { |r| import r }
</code></p>

<p>This will load any custom tasks from <code>lib/capistrano/tasks</code>, which we will later define.</p>

<h1>Roll up Your Sleeves</h1>

<p>One cool thing about Capistrano is it’s designed to work with different deployment scenarios. You could, for example, have both a production server running your “live” application and a staging server meant for testing newly developed features before they’re pushed to the production server. In other words, you’d have two deployment stages: production and staging. When we ran <code>cap install</code>, Capistrano actually already created the necessary files for this; they’re located inside the <code>/config/deploy</code> directory and are named <code>production.rb</code> and <code>staging.rb</code>, respectively. We’ll use them to define stage-specific configurations, while configurations that are meant to be shared across all stages will be set in <code>config/deploy.rb</code>, and that’s where we’ll start first.</p>

<h2>General Configuration</h2>

<p>Below is how my <code>deploy.rb</code> file looks like for Phindee:</p>

<p>``` ruby deploy.rb
lock &ldquo;3.1.0&rdquo;</p>

<p>set :application, &ldquo;phindee&rdquo;
set :repo_url, &ldquo;git@github.com:vladigleba/phindee.git&rdquo;</p>

<p>set :deploy_to, &ldquo;/var/www/#{fetch(:application}&rdquo;
set :deploy_user, &ldquo;bob&rdquo;</p>

<p>set :rbenv_type, :user # or :system, depends on your rbenv setup
set :rbenv_ruby, &ldquo;2.1.0&rdquo;
set :rbenv_prefix, &ldquo;RBENV_ROOT=#{fetch(:rbenv_path)} RBENV_VERSION=#{fetch(:rbenv_ruby)} #{fetch(:rbenv_path)}/bin/rbenv exec&rdquo;
set :rbenv_map_bins, %w{rake gem bundle ruby rails}
set :rbenv_roles, :all # default value</p>

<p>set :linked_files, %w{config/database.yml}
set :linked_dirs, %w{bin log tmp/pids tmp/cache tmp/sockets vendor/bundle public/system}</p>

<p>set :keep_releases, 5
```</p>

<p>The very first line locks the configurations in this file to Capistrano 3.1, and if you have any other version installed, the file won’t run. (This is designed to help prevent configurations from braking between version updates.)</p>

<p>Next, we’re using the <code>set()</code> function to initialize the <code>:application</code> variable to “phindee.” (We’ll retrieve this variable’s value later using the corresponding <code>fetch()</code> function.) We’re also setting the <code>:repo_url</code> variable to the URL of the GitHub repository containing your code so Capistrano  knows where to look when we deploy. By the way, if your code is on a branch other than “master,” you’ll need to specify its name by adding <code>set :branch, “branch-name”</code>; otherwise, this is not needed because Capistrano sets it to “master” by default.</p>

<p>The next line sets the <code>:deploy_to</code> variable to the path where you want Capistrano storing the code it downloads from GitHub. This should be the same path you previously set in <code>unicorn.rb</code>, but without the <code>/current</code> directory appended to it. This is because <code>/current</code> represents the directory with the latest deploy code, while Capistrano is interested in the general app directory.</p>

<p><code>:deploy_user</code> is then set to the user Capistrano will be deploying as, and this should match the user you created when you setup your server in <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>.</p>

<p>The next few lines set variables needed by rbenv, and I actually copied and pasted these lines from the <code>capistrano-rbenv</code> <a href="https://github.com/capistrano/rbenv">README file</a>. The key variable here is <code>:rbenv_ruby</code>, which sets the Ruby version that rbenv installed on your machine, and you can run <code>ls ~/.rbenv/versions</code> in the command line to find which version that is. If this is not set correctly, the deploy will fail.</p>

<p>The other variable worth mentioning here is <code>:rbenv_type</code>. We could set it to <code>:system</code> if rbenv was installed system-wide on our machine, but since we installed rbenv on a per-user basis inside <code>~/.rbenv</code>, we&rsquo;re setting it to <code>:user</code>. System-wide installs can lead to problems with permissions, and it’s generally cleaner to just do a per-user install. The other three variables don’t need to be modified, and you can leave them the way they are.</p>

<p>Moving on, we’re setting the <code>:linked_files</code> variable to an array of strings initialized to <code>config/database.yml</code>. This tells Capistrano to store our app’s <code>config/database.yml</code> file inside a directory called <code>/shared</code>, which is meant for any files we want to persist between deploys. Since the contents of <code>database.yml</code> won’t change between deploys, it’s a good idea to store it there.</p>

<p>Similarly, <code>:linked_dirs</code> contains <em>directories</em> that are meant to persist between deploys, and they too will be stored inside <code>/shared</code>. These include directories containing things like log files, Unicorn sockets, and <code>.pid</code> files that will all stay the same between deploys.</p>

<p>And finally, <code>:keep_releases</code> tells Capistrano to only keep the last 5 deploys and discard everything else. This can be useful whenever you need to rollback to a previous release, but you also don&rsquo;t want releases piling up, so it&rsquo;s best not to set this number too high.</p>

<h2>Stage-Specific Configuration</h2>

<p>Now that <code>deploy.rb</code> is configured, we’ll move on to defining stage-specific configurations. Since I currently don’t have a separate environment for staging, I’ll only be going over the <code>config/deploy/production.rb</code> file, and you can just leave <code>staging.rb</code> the way it is by default. Below is how my <code>production.rb</code> file looks like:</p>

<p>``` ruby production.rb
set :stage, :production
set :rails_env, :production</p>

<p>server &lsquo;xxx.xxx.xxx.xxx&rsquo;, user: &lsquo;bob&rsquo;, port: 12345, roles: %w{web app db}, primary: true
```</p>

<p>As you can see, there isn’t much going on here. We’re first setting the <code>:stage</code> variable to <code>:production</code> to let Capistrano know that this file is meant for production. We’re also setting the <code>:rails_env</code> variable to the same thing to make sure Rails runs in the production environment. But the key line is the last line, which tells Capistrano how to access our VPS server. Make sure you replace the Xs with the IP address of the server you setup in part 1, along with the user and port number it&rsquo;s set up with.</p>

<p>We’re then using the <code>:roles</code> variable to let Capistrano know that our database server (PostgreSQL) represented by <code>db</code>, web server (Nginx) represented by <code>web</code>, and application server (Unicorn) represented by <code>app</code> all run on the same machine. Apps with lots of traffic, on the other hand, might have multiple separate physical servers for each of these. Setting <code>:primary</code> to <code>true</code> then tells Capistrano that this is our primary database server, and Capistrano will run migrations only on the one we designate as <code>:primary</code>. Even if we’re running all our servers on the same physical machine, setting <code>:primary</code> is still necessary.</p>

<h1>Enabling Agent Forwarding</h1>

<p>Now that Capistrano knows how to access our VPS, we need to make sure it can also access our code on GitHub. We’ll be using agent forwarding to allow us to reuse the local key we generated in part 1 to authenticate with GitHub. In order for this to work, we’ll need to add the key to GitHub, and you can do so by following step 3 on <a href="https://help.github.com/articles/generating-ssh-keys#step-3-add-your-ssh-key-to-github">this GitHub page</a>.</p>

<p>To enable agent forwarding in Capistrano 2, you had explicitly set it in <code>deploy.rb</code>, but in Capistrano 3, it’s already taken care of and enabled by default. The only thing we have left to do is log in to our VPS and run the following command to add github.com to the list of known hosts; this ensures Capistrano won’t have any problems with it being unknown when it tries downloading your code from GitHub to your server:</p>

<p><code>bash
ssh git@github.com
</code></p>

<p>You’ll get a warning asking if you’re sure you want to continue connecting. Verify that the key fingerprint matches the one you just added to GitHub, and enter “yes”. If you get an “access denied” message, see <a href="https://help.github.com/articles/error-permission-denied-publickey">this page</a> for potential solutions. If you’re experiencing some other agent forwarding problems, <a href="https://help.github.com/articles/using-ssh-agent-forwarding#troubleshooting">this page</a> might help you out.</p>

<h1>Setting Permissions</h1>

<p>If you look at <code>deploy.rb</code>, you’ll notice I set the <code>:deploy_to</code> variable to “/var/www/phindee,” but on my VPS, the <code>/var</code> directory doesn’t yet contain the <code>/www</code> directory. That’s not a problem since Capistrano will create it for me through the user <code>bob</code>, as specified in <code>deploy.rb</code>, but it needs write permissions to do so.</p>

<p>If you read <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>, you’ll remember we created a group called <code>deployers</code> to contain users with deployment privileges and added the user <code>bob</code> into it. This means we can give the necessary permissions <code>bob</code> will need by simply giving them to <code>deployers</code>, and since <code>bob</code> is a member of the group, he will automatically inherit them.</p>

<p>I’m already logged in to my VPS as <code>bob</code>, and I can change the <code>/var</code> directory’s group to <code>deployers</code> with the following command:</p>

<p><code>bash
sudo chgrp deployers /var
</code></p>

<p>We can then give this group write permissions so its members can create directories within <code>/var</code>:</p>

<p><code>bash
sudo chmod g+w /var
</code></p>

<p>There are two other places where we need to repeat this process. The first is the <code>/etc/nginx/sites-enabled</code> directory, which Nginx uses to store its configuration files, and this is where our <code>config/nginx.conf</code> file that we created in <a href="/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/">part 4</a> will go. But we actually won’t be storing the file itself there; we’ll create a symlink to it, instead. This will make our deploys easier to manage because we won’t need to add our <code>nginx.conf</code> file to the <code>/etc/nginx/sites-enabled</code> directory <em>every</em> time we deploy. We can simply symlink it since Capistrano will always store our latest deploy code in the same place (<code>/var/www/phindee/current</code>).</p>

<p>Same thing is needed for the <code>config/unicorn_init.sh</code> file from <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>. We’ll need to create a symlink inside <code>/etc/init.d</code>, since that’s the directory Linux uses to store all the shell scripts used to manage the various services installed on the system. When we installed Nginx in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, for example, a shell script was automatically installed there to help us manage Nginx, and it will be invoked whenever we run a command like <code>sudo service nginx restart</code>. There is nothing like this for Unicorn yet, which is why we need to create a symlink to our <code>unicorn_init.sh</code> script to give us similar functionality.</p>

<p>In order for Capistrano to create symlinks, it needs write permissions in the relevant directories. We can give them with the following commands:</p>

<p>``` bash
sudo chgrp deployers /etc/nginx/sites-enabled
sudo chmod g+w /etc/nginx/sites-enabled</p>

<p>sudo chgrp deployers /etc/init.d
sudo chmod g+w /etc/init.d
```</p>

<p>And now Capistrano should have the necessary permissions to do its work.</p>

<p>Having Capistrano configured, we’re ready to move on and start writing custom tasks to help us deploy our code, and that’s exactly what we’ll do in the next and last post of this series. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you&rsquo;ll get it delivered to your inbox as soon as it’s released.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 4: Configuring Nginx]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/"/>
    <updated>2014-03-27T12:50:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx</id>
    <content type="html"><![CDATA[<p>I talked about how I configured Unicorn for <a href="http://phindee.com/">Phindee</a> in <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>, and now I&rsquo;ll cover how I configured Nginx. While Unicorn will handle requests for pages dynamically generated by Rails, Nginx will handle requests for static assets, like stylesheets, scripts, images, and fonts. If you’re wondering why I chose Nginx over Apache, see <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a> for the explanation.</p>

<!-- more -->


<p>Alright, since there is quite a bit to cover, we’ll jump right in. We’ll start by creating a file called <code>nginx.conf</code> inside our app’s <code>/config</code> directory on our local computer. Here’s how mine looks like:</p>

<p>``` nginx nginx.conf
worker_processes 1;</p>

<p>events {
  worker_connections 1024;
}</p>

<p>upstream unicorn {
  server unix:/tmp/unicorn.phindee.sock fail_timeout=0;
}</p>

<p>server {
  server_name www.phindee.com;
  return 301 $scheme://phindee.com$request_uri;
}</p>

<p>server {
  listen 80 default deferred;
  server_name phindee.com;
  root /var/www/phindee/current/public;</p>

<p> location ^~ /assets/ {</p>

<pre><code>gzip_static on;
expires max;
add_header Cache-Control public;
</code></pre>

<p>  }</p>

<p>  try_files $uri/index.html $uri @unicorn;
  location @unicorn {</p>

<pre><code>proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header Host $http_host;
proxy_redirect off;
proxy_pass http://unicorn;
</code></pre>

<p>  }</p>

<p>  error_page 500 502 503 504 /500.html;
  keepalive_timeout 10;
}
```</p>

<p>You might have noticed that the first thing we do is specify the number of workers to run. If you read part 3, this will sound familiar, because Nginx, just like Unicorn, has a master process managing all the workers, and the workers are the ones responsible for processing requests from clients. Unlike Unicorn, Nginx also has a cache loader process that checks and/or populates the cache with metadata, as well a cache manager process that’s responsible for cache expiration. Together, they keep Nginx internals running quickly and efficiently.</p>

<h1>A Bit on Workers</h1>

<p>As you can see, we used the <code>worker_processes</code> directive to tell Nginx to run one worker, which is the default. We then used the <code>worker_connections</code> directive inside the <code>events</code> block to specify that the maximum number of connections a worker can accept is 1024, which is also the default. Since we’re using defaults for both directives, it wasn’t necessary to add them to our file at all, but I chose to include them for completeness.</p>

<p>Given our current configuration, our server will be able to accept a total of 1024 simultaneous connections. If you want to increase this, it’s generally best to increase the <code>worker_connections</code> value before increasing the number of workers. Remember, each worker is a single-threaded process, so whenever you increase the number of workers, you’re also increasing the total amount of memory that will be used. Having one worker process that’s capable of handling 1024 connections is more than enough for a low-traffic app, however.</p>

<h1>Hooking up with Unicorn and Handling Redirects</h1>

<p>Since Nginx is not capable of handling requests for pages that are dynamically generated by Rails, we need to tell it to somehow pass such requests off to Unicorn. We’ll take the first step to accomplishing this by defining an <code>upstream</code> block called <code>unicorn</code>, inside which we point the server to the same Unix socket that we used in our <code>unicorn.rb</code> file from <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>. This is just the first step, however, and more work needs to be done to get this working, as you’ll see later. By the way, in case you’re wondering, setting <code>fail_timeout</code> to 0 is necessary for Nginx to correctly handle Unicorn timing out due to its worker being killed when it takes longer than 30 seconds to respond, as specified in <code>unicorn.rb</code>.</p>

<p>The <code>server</code> block right below the <code>upstream</code> block is there to redirect a request for &ldquo;www.phindee.com&rdquo; to &ldquo;phindee.com&rdquo;. The <code>server_name</code> directive specifies the URL we’re redirecting from, while the <code>return</code> directive specifies where to redirect to. (Notice we’re returning a 301 status code to specify a permanent redirection.) The <code>$scheme</code> variable stores the HTTP scheme (i.e. http, https), while <code>$request_uri</code> stores the unmodified URI of a client request, which includes the arguments, but not the host name (e.g. &ldquo;/foo/bar.php?arg=baz&rdquo;).</p>

<h1>Where the Meat Is</h1>

<p>The next <code>server</code> block contains the main configuration. The <code>listen</code> directive inside it tells Nginx to listen on port 80, and the <code>server_name</code> directive right below specifies the domain name that Nginx will try to match, which is &ldquo;phindee.com&rdquo; in my case.</p>

<p>Specifying <code>default</code> in the <code>listen</code> directive, by the way, tells Nginx to use this server block by default if it can’t find a matching domain name, which means I could technically leave out the <code>server_name</code> directive completely, and everything would still work because of <code>default</code>, but I like to leave it in for readability. And finally, I added the <code>deferred</code> option since I’m running this on Linux, which tells Nginx to use the <code>TCP_DEFER_ACCEPT</code> option to <a href="http://www.techrepublic.com/article/take-advantage-of-tcp-ip-options-to-optimize-data-transmission/">speed up performance</a> by reducing the amount of preliminary work that happens between a client and the server.</p>

<p>Moving along, the <code>root</code> directive specifies the directory in which Nginx will look to handle requests for static files. This is basically the directory we specified inside <code>unicorn.rb</code>, except it has an additional <code>/public</code> directory appended to the end of it. It corresponds to your app’s <code>/public</code> directory on your local computer and is the place where your static files are and will reside. Currently, it only contains various error pages, a favicon, and a <code>robots.txt</code> file for search engines. When we later deploy with Capistrano, it’ll contain all our assets as well, including stylesheets, scripts, images, and fonts.</p>

<h1>Handling Asset Requests</h1>

<p>Just like the <code>server_name</code> directive handles requests for domain names, the <code>location</code> directive handles requests for specific files and folders. The caret and tilde (^~) tells Nginx to do a regular expression match on <code>/assets/</code> and to stop searching as soon as it finds a match (see the <a href="https://library.linode.com/web-servers/nginx/configuration/basic#sph_location-file-and-folder-configuration">Linode Guide</a> to learn more).</p>

<p>By setting the <code>gzip_static</code> directive to <code>on</code>, we’re then telling Nginx to look for an already pre-compressed <code>.gz</code> file <em>before</em> proceeding to compress it. This prevents Nginx from compressing the same file each time it is requested.</p>

<p>The <code>expires</code> directive then makes the response cacheable and marks it with an expiry date set to <code>max</code>, which is equivalent to December 31st, 2037. This tells browsers and any caching servers to not request these assets again until the specified date. Of course, if we make changes to our stylesheets, for example, Rails will change the filename and browsers will still receive the latest version, which will then also be cached.</p>

<p>Using the <code>expires</code> directive, however, is an outdated method of specifying caching, and it’s recommended to use <code>Cache-Control</code> header instead. The next line in the code does just that through the <code>add_header</code> directive. (The reason we include  <code>expires</code> is to make things backward-compatible.) It’s possible, by the way, to set <code>Cache-Control</code> to either <code>public</code> or <code>private</code>, and I’m setting it to <code>public</code> because we’re caching assets that are meant to be used by everybody, whereas <code>private</code> would mean they’re unique to individual users (see <a href="http://stackoverflow.com/questions/3492319/private-vs-public-in-cache-control">Stack Overflow</a> to learn more).</p>

<h1>Trying to Find a Match</h1>

<p>The next line is the <code>try_files</code> directive, which is there for requests that didn’t match with any <code>location</code> blocks. In our case, it tries to match non-asset requests. The <code>$uri</code> variable inside it contains the current request URI, minus the arguments, protocol, and host name, so if we typed in &ldquo;phindee.com/foobar&rdquo; into the address bar, the <code>$uri</code> would be &ldquo;/foobar&rdquo;, and given our <code>try_files</code> directive, Nginx would try to first match a <code>var/www/phindee/current/public/foobar/index.html</code> file. If it found no such file, it would then try to match the <code>/foobar</code> directory itself, and if that didn’t work, it would then pass the request off to Unicorn through a named location, which is defined next through the <code>location</code> directive and called <code>@unicorn</code>.</p>

<p>Inside the named location, the <code>proxy_pass</code> directive does all the heavy lifting. We set it to <code>http://unicorn</code> so that it points to the <code>upstream</code> block called <code>unicorn</code>, which we already defined, and the request is then handled by the Unicorn socket defined there. The two <code>proxy_set_header</code> directives then append additional headers needed for Unicorn, while <code>proxy_redirect</code> set to <code>off</code> prevents Nginx from doing any redirect handling. (There is a sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file on GitHub</a> with comments explaining why this is necessary.)</p>

<h1>Last Few Lines</h1>

<p>Alright, we’re down to the last two lines. <code>error_page</code> makes sure that our app’s <code>500.html</code> page is shown for any 500-related errors, while <code>keepalive_timeout</code> tells Nginx to retain keep-alive connections (also known as persistent connections) for up to 10 seconds and close them if they exceed that time. The main concern when choosing the amount of time is mobile devices on slow networks, but I think 10 seconds should be enough.</p>

<p>Keep-alive connections, by the way, send multiple HTTP requests in a single connection, as opposed to opening a new connection for each request; in HTTP 1.1, all connections are persistent by default, which means stylesheets, scripts, images, and fonts, for example, would all be sent using a single connection.</p>

<p>These are, of course, not all the options you can specify. If you’d like to learn about the additional ones, feel free to read through the comments in the sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file</a> I mentioned earlier.</p>

<p>And that wraps up part 4. I will introduce Capistrano in the <a href="/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/">next post</a> and will explain how I configured it for Phindee. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you&rsquo;ll get it delivered to your inbox as soon as it’s released.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 3: Configuring Unicorn]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/"/>
    <updated>2014-03-21T10:08:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn</id>
    <content type="html"><![CDATA[<p>Having covered how to install the technology stack powering Phindee in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, I will now shift gears and talk about how I configured Unicorn. I already explained why I chose to install Nginx, but I haven’t yet explained why I chose Unicorn, so here we go.</p>

<!-- more -->


<p><a href="http://unicorn.bogomips.org/">Unicorn</a> is an HTTP server for Ruby. It&rsquo;s designed to be used in a production environment, unlike WEBrick, which is designed for running your app on your local computer. Because it&rsquo;s fast, efficient, and offers tons of cool features, like load balancing and rolling restarts, Unicorn has become a popular production server for Rails apps.</p>

<h1>Comparing Unicorn with Passenger</h1>

<p>When I deployed Phindee for the first time, however, I actually used the open source version of <a href="https://www.phusionpassenger.com/">Phusion Passenger</a>, due to the fact that it was (and is) easier to setup than Unicorn. My main concern, at the time, was to have a functioning app deployed as soon as possible, with as little effort as possible, and Passenger helped me do just that.</p>

<p>Eventually, I reached a point where I was ready for something that I could configure myself, and Unicorn seemed like a good next step. But if you’re a beginner, Passenger will be the easiest to start with since it’s designed to integrate into Nginx directly and, therefore, requires less work to setup and maintain. You will have to pay for the Enterprise version, however, if you want advanced features like error-resistant, zero-downtime deploys, which come for free with Unicorn.</p>

<h2>Do One Thing, Do It Well</h2>

<p>The reason why I like Unicorn is due to its philosophy of doing a few things well. An example of this is load balancing, which Unicorn hands off to the operating system entirely. When Unicorn starts, its master process spawns (forks) a configured number of processes called workers. These workers then handle the incoming requests to your app and only accept a request when they’re ready.</p>

<p>But it’s the operating system that handles the forking, as well as the distribution of requests between processes that are ready to accept, not Unicorn. What Unicorn does is the actual monitoring of workers themselves through the master process. If a worker, for example, takes too much time to complete a task, the master process will kill it and spawn a new one.</p>

<h2>Deploys Done Right</h2>

<p>What this design can achieve is error-resistant, zero-downtime deploys. Error-resistant deploys ensure that if something goes wrong during a deploy, your app will remain online and serve incoming requests using the old code. This is possible because Unicorn doesn’t kill off old workers until new workers have successfully forked, which means your old workers will stay alive if something goes wrong with the new ones.</p>

<p>Zero-downtime deploys work in a similar manner. We can send a signal to the master process telling it to start a new master, and this new master will then begin reloading our new code. Once it’s fully loaded, the new master will fork its workers. The first worker forked will notice there is still an old master running, and it’ll send a signal telling it to start gracefully shutting down its workers. When all workers finish serving their current requests, the old master then dies, and our app is fully reloaded with new code.</p>

<p>Passenger supports rolling restarts like this as well, but they only come with the paid Passenger Enterprise version. One advantage the Enterprise version provides, however, is it restarts the processes one-by-one, which requires less memory. Rolling restarts with Unicorn, on the other hand, are done all at once and temporarily require twice the memory usage. It is possible, of course, to script one-by-one rolling restarts in Unicorn, but Passenger does this automatically for you.</p>

<h1>How about Puma?</h1>

<p>Another alternative to Unicorn and Passenger is Puma. Whereas Unicorn and Passenger achieve concurrency through the use of forks, Puma achieves it by running multiple threads in a single process. Of course, this means that your code must be thread-safe, but since Rails 4 is thread-safe by default, this shouldn’t be an issue.</p>

<p>Because threading requires less memory than forking, Puma will be more memory efficient than a similar Unicorn setup. Puma, however, does not do rolling restarts, nor does watch for and restart failed processes, like Unicorn, which means you’ll need a service like <a href="http://mmonit.com/monit/">Monit</a> that monitors and restarts them for you. As with any technology, pick whatever best meets your needs.</p>

<h1>Installing and Configuring Unicorn</h1>

<p>With that out of the way, we’re now ready to start working with Unicorn. We’ll begin by adding the following line to our app’s <code>Gemfile</code> on our local computer:</p>

<p><code>ruby Gemfile
gem 'unicorn', '~&gt; 4.8.0’
</code></p>

<p>Make sure you change the version number to whatever’s the most recent one at the time of your install. The <code>~&gt;</code> notation means that any future minor updates (e.g., from 4.0.0 to 4.0.1) will be installed, but major ones (e.g., from 4.0 to 4.1) won’t be. Major updates can sometimes introduce unexpected behavior in your app, so it’s best to limit the updates to minor releases only.</p>

<p>We&rsquo;ll then install Unicorn by running <code>bundle</code> in the root path of our app, and Bundler, which we installed in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, will take care of the install for us.</p>

<p>Having Unicorn installed, we can begin configuring it. We’ll start by creating a file called <code>unicorn.rb</code> on our local computer inside the <code>/config</code> directory of our Rails application. This is how my file for Phindee looks:</p>

<p>``` ruby unicorn.rb
root = &ldquo;/var/www/phindee/current&rdquo;
working_directory root
pid &ldquo;#{root}/tmp/pids/unicorn.pid&rdquo;
stderr_path &ldquo;#{root}/log/unicorn.log&rdquo;
stdout_path &ldquo;#{root}/log/unicorn.log&rdquo;</p>

<p>listen &ldquo;/tmp/unicorn.phindee.sock&rdquo;
worker_processes 2
timeout 30
```</p>

<p>The first variable <code>root</code> represents the path to the root directory of our app, which I&rsquo;ve set to <code>/var/www/phindee/current</code>. Generally, web apps are stored inside <code>/var/www</code> on Unix since the <code>/var</code> directory is designated for files that increase in size over time, which is the case with most web apps, and a <code>/www</code> directory is typically created inside <code>/var</code> to store files meant for the web. I then have a <code>/phindee</code> directory specified inside <code>/www</code> to store all things related to Phindee, as well as a <code>current</code> directory, which Capistrano will later create and use to store the latest deployment code. You don&rsquo;t have to actually create these directories now, as Capistrano we&rsquo;ll create them itself when it runs.</p>

<p>Below is what the rest of the configurations mean:</p>

<ul>
<li><p><code>working_directory</code> specifies exactly what is says&mdash;the app’s working directory&mdash; and it’s set to the variable <code>root</code>, which we just defined.</p></li>
<li><p><code>pid</code> specifies the path to a <code>.pid</code> file that will store the process ID of Unicorn’s master process, which can be later used to stop the process itself. These files are typically stored inside the <code>/tmp</code> directory since they exist only while Unicorn is running, so you can leave this line the way it is.</p></li>
<li><p><code>stderr_path</code> and <code>stdout_path</code> specify the path to <code>stderr</code> and <code>stdout</code>. If you’re not familiar with what they mean, when a Unix program starts up, it has three streams opened for it: one for input called “standard input” (abbreviated <code>stdin</code>), one for output called “standard output” (abbreviated <code>stdout</code>), and one for printing error messages called “standard error” (abbreviated <code>stderr</code>). Given our configuration, this means that any error messages written by our Rails app to the <code>stderr</code> stream will get written to the <code>.log</code> file specified in the <code>stderr_path</code>. It’s common to point <code>stdout_path</code> to the same location as <code>stderr_path</code> and store them both inside the <code>/log</code> directory.</p></li>
<li><p><code>listen</code> specifies the path to a socket that will listen for a client wanting to make a connection request. If you’re unfamiliar with this, a socket is basically a software object consisting of a port number that’s attached to an IP address. It allows clients and servers to communicate with one another by writing to and reading from their sockets. Since they’re running only when Unicorn is running, they’re usually stored inside the <code>/tmp</code> directory as well.</p></li>
<li><p><code>worker_processes</code> specifies the number of workers that the master process will fork for client request handling. The more workers you set, the more memory you’ll need, and since I don’t have a large amount of memory on my VPS, I decided to set mine to two. This should be enough for a low-traffic app, but once your traffic rises, the number of workers, as well as the amount of memory available to your server, will need to rise with it.</p></li>
<li><p><code>timeout</code> specifies the maximum number of seconds a worker can take to respond to a request before the master kills it and forks a new one. 30 seconds is a good value to put here since whenever a worker takes longer than this to respond, it’s usually safe to assume there is something wrong with the worker itself.</p></li>
</ul>


<p>You can get a complete list of all the other possible configuration options by taking a look Unicorn’s <a href="http://unicorn.bogomips.org/Unicorn/Configurator.html">Configurator Module</a>.</p>

<h1>Managing Unicorn Processes</h1>

<p>Having Unicorn configured, we’ll now need to setup a way for us to manage the Unicorn processes themselves.</p>

<p>Unicorn uses signals to communicate with its processes, and you can find a full explanation of all the available signals <a href="http://unicorn.bogomips.org/SIGNALS.html">here</a>. But sending these signals manually would be a pain. I recommend using a <a href="https://github.com/railscasts/335-deploying-to-a-vps/blob/master/blog-nginx/config/unicorn_init.sh">script on GitHub</a> to automate this process for you. Go ahead and create your own <code>unicorn_init.sh</code> file inside your app’s <code>/config</code> directory and copy/paste the script’s code into it.</p>

<p>All the variables you can change are defined at the beginning of the script. You&rsquo;ll need to set the <code>APP_ROOT</code> variable to the same path that the <code>root</code> variable in <code>unicorn.rb</code> is set to, and you&rsquo;ll want to set the <code>AS_USER</code> variable to the user you set up your server with in <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>. Lastly, you&rsquo;ll want to modify the <code>CMD</code> variable by adding <code>~/.rbenv/bin/rbenv exec</code> right after <code>cd $APP_ROOT;</code>, but right before <code>bundle exec unicorn ...</code>, which is necessary so that the correct environment variables are set when we run the command remotely through Capistrano.</p>

<p>If you’re inside the root directory of your Rails app, you can then make the script executable with the following command:</p>

<p><code>bash
chmod +x config/unicorn_init.sh
</code></p>

<p>I’d like to point out that the way <code>unicorn.rb</code> and <code>unicorn_init.sh</code> is currently setup, Unicorn won’t be doing rolling restarts. If you look at <code>unicorn_init.sh</code>, for example, you’ll notice that it sends a <code>HUP</code> signal when you run the script’s <code>restart</code> command. This signal doesn’t spawn a new master process, the way a rolling restart would do; it simply reloads the <code>unicorn.rb</code> file and gracefully restarts all the workers using the same master process.</p>

<p>You’d need to use the <code>USR2</code> signal for a rolling restart (which is actually what happens when you run the script’s <code>upgrade</code> command). But even then, there are still additional steps you’ll need to take to make everything runs smoothly, like making sure your database connections carry over, as well as ensuring any changes to the database are compatible with the older code.</p>

<p>I won’t be explaining how to do this here because I haven’t yet set it up myself, but if you’re curious, there is a good <a href="http://www.justinappears.com/blog/2-no-downtime-deploys-with-unicorn/">blog post</a> explaining all the nuances you need to be aware of. Phindee is currently a small, low-traffic app and its code is reloaded within seconds, so I’m not worried about users waiting for their requests and don’t see a need for rolling restarts at the moment, but I’m hoping the need presents itself soon.</p>

<p>Having configured Unicorn, we&rsquo;ll move on to configuring Nginx in <a href="/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/">part 4</a>. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and the post will be delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 2: Setting up the Server]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/"/>
    <updated>2014-03-14T09:45:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server</id>
    <content type="html"><![CDATA[<p>In <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>, I talked about choosing a VPS provider, creating a new Ubuntu instance, and configuring it to be more secure. Now, in part 2, I&rsquo;ll talk about installing the technology stack behind <a href="http://phindee.com/">Phindee</a>: Node.js, Nginx, PostgreSQL, rbenv, Ruby, and Bundler.</p>

<!-- more -->


<h1>But First!</h1>

<p>Before we proceed any further, make sure you’re logged in as the user you created in part 1; if you’re already logged in as <code>root</code>, you can switch to the correct user with the following command:</p>

<p><code>bash
su - username
</code></p>

<p>Once logged in, we’ll run the following command to fetch the latest updates for the packages on our system:</p>

<p><code>bash
sudo apt-get update
</code></p>

<p>We’ll follow this up with the command to install the necessary package updates:</p>

<p><code>bash
sudo apt-get upgrade
</code></p>

<p>If the command found any updates to install, it will ask if you want to continue with the install; you can enter “y” to do so. Once it finishes, we’ll be ready begin.</p>

<h1>Setting Timezones and Installing Mail</h1>

<p>We’ll start by setting the correct timezone:</p>

<p><code>bash
sudo dpkg-reconfigure tzdata
</code></p>

<p>You’ll be asked to choose your country and timezone, after which your server’s local time will be displayed; if it displays the correct time, you’re good to go.</p>

<p>We’ll install <code>postfix</code> and <code>telnet</code> next to enable our Rails app to send email:</p>

<p><code>bash
sudo apt-get -y install telnet postfix
</code></p>

<p>Feel free to just press “enter” through all the prompts and keep all the defaults.</p>

<p>Next, we’ll install some useful packages we’ll later need, among them <code>python-software-properties</code>, which will allow us to easily add new repositories to the <code>apt</code> package handling system:</p>

<p><code>bash
sudo apt-get -y install curl git-core python-software-properties
</code></p>

<p>Having the ability to add new repositories this way allows us to install the most recent updates since the default <code>apt-get</code> repositories typically don’t receive the latest updates immediately.</p>

<h1>Installing Node.js</h1>

<p>We’ll actually put this ability to use right now by adding a new repository for <a href="http://nodejs.org/">Node.js</a>:</p>

<p><code>bash
sudo add-apt-repository ppa:chris-lea/node.js
</code></p>

<p>We’ll then update the created repository with the latest Node.js code available:</p>

<p><code>bash
sudo apt-get -y update
</code></p>

<p>and install it, like so:</p>

<p><code>bash
sudo apt-get -y install nodejs
</code></p>

<p>We could’ve avoided adding a new repo and just used the traditional <code>apt-get</code> method to do the install, but this would’ve installed an older version of Node.js. Because Node.js is under active development and things are added quite frequently, it’s important to run the latest possible version. This might not matter as much for software that doesn’t have an aggressive update schedule, but this is the route we’ll take for Node.js.</p>

<p>By the way, if you’re wondering why we’re installing Node.js, the reason is it provides a good way to execute JavaScript, and we’ll need this for the Rails <a href="http://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>.</p>

<h1>Installing Nginx</h1>

<p>Next, we’ll install a web server called <a href="http://wiki.nginx.org/Main">Nginx</a>, which will handle all our static requests, such as stylesheets, scripts, images, and fonts. Its low memory usage and ability to serve static content quickly and efficiently make it a popular alternative to Apache and an excellent choice for sites running on a Virtual Private Server (VPS). What makes Nginx efficient is the fact that it’s an event-based server, while Apache, on the other hand, is process-based. An event-based server doesn&rsquo;t spawn new processes or threads for each request the way a process-based one does, and this means lower memory usage and faster responses.</p>

<p>We’ll install it by adding another repository:</p>

<p><code>bash
sudo add-apt-repository ppa:nginx/stable
sudo apt-get -y update
sudo apt-get -y install nginx
</code></p>

<p>Once it’s installed, we can start it up with:</p>

<p><code>bash
sudo service nginx start
</code></p>

<p>If you now visit your server’s IP address, you should see a simple page proclaiming “Welcome to nginx!”</p>

<h1>Installing PostgreSQL</h1>

<p>Most modern apps need to store some sort of data, and there are a plethora of open source databases available, like <a href="https://www.mysql.com/">MySQL</a>, <a href="https://sqlite.org/">SQLite</a>, and <a href="http://www.postgresql.org/">PostgreSQL</a>. I never tried MySQL, but when I first started out, I used SQLite, the default database for Rails apps, because I liked its simplicity and saw no need for something more sophisticated. As my needs have evolved, however, so has my database, and I recently decided to switch to PostgreSQL because of its support for a fast key-value store called HStore and its ability to do full-text search, both of which I&rsquo;ll need for Phindee.</p>

<p>We’ll install it with <code>apt-get</code>:</p>

<p><code>bash
sudo apt-get install postgresql postgresql-contrib
</code></p>

<p>We can then start Postgres as the default <code>postgres</code> user with the following command:</p>

<p><code>bash
sudo -u postgres psql
</code></p>

<p>Had we not specified the default user, it would’ve tried to use the user we’re logged in with on our VPS, and Postgres would’ve complained that the role doesn’t exist since there is no such user created in Postgres. This makes it necessary to login as the default <code>postgres</code> user.</p>

<p>Once logged in, we’ll setup a password for <code>postgres</code>:</p>

<p><code>sql
\password
</code></p>

<p>We’ll also create a new user called <code>admin</code>, followed by a database called <code>phindee</code>, which will be owned by <code>admin</code>:</p>

<p><code>sql
create user admin with password 'secret';
create database phindee owner admin;
</code></p>

<p>Having the basics setup, we can now quit Postgres:</p>

<p><code>sql
\quit
</code></p>

<h1>Installing rbenv</h1>

<p><a href="https://github.com/sstephenson/rbenv">rbenv</a> is a tool that helps you manage the Ruby versions installed on your system, thereby allowing you to easily switch between them. Whenever you want to play with a new version of Rails&mdash;without messing up your current setup&mdash;rbenv will come in handy.</p>

<p>You may be familiar with another Ruby version manager called <a href="https://rvm.io/">RVM</a>. I used it myself for a while, before switching over to rbenv. It’s not that one is “better” than the other; it’s about which one is better suited for <em>your</em> needs. I made the switch because rbenv is more lightweight than RVM, its design feels cleaner, and it has a cool name.</p>

<p>rbenv will suite you well if you’re starting out; otherwise, install whatever best meets your needs. By the way, it’s worth mentioning that since rbenv is incompatible with RVM, you won’t be able to run them side by side.</p>

<p>Alright, we can install rbenv like so:</p>

<p><code>bash
sudo curl -L https://raw.github.com/fesplugas/rbenv-installer/master/bin/rbenv-installer | bash
</code></p>

<p>This will run a script that will do most of the install for us. In the end, you’ll receive a message telling you to add rbenv to the load path, and you can do so by opening up <code>bash_profile</code>:</p>

<p><code>bash
sudo nano ~/.bash_profile
</code></p>

<p>and copying/pasting the code that was outputted by the message. We’ll then need to reload the file for the changes to take effect:</p>

<p><code>bash
. ~/.bash_profile
</code></p>

<p>We’re almost ready to install Ruby, but before we do, we first need to install the C compiler and the Make utility, which is needed for the Ruby install. We can do so by installing a package called <code>build-essential</code>, along with some additional packages we’ll need later on:</p>

<p><code>bash
sudo apt-get install zlib1g-dev build-essential libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libpq-dev
</code></p>

<p>With the packages installed, we’re now ready to install Ruby itself.</p>

<h1>Installing Ruby</h1>

<p>To see a list of all the Ruby versions available, we can run the following command:</p>

<p><code>bash
rbenv install --list
</code></p>

<p>I chose to install version 2.1.0, as that was the latest one at the time:</p>

<p><code>bash
rbenv install 2.1.0
</code></p>

<p>This will take a few minutes to run&mdash;and that’s probably an understatement&mdash;but once it finishes, we’ll make the version it just installed the default Ruby version on our server:</p>

<p><code>bash
rbenv global 2.1.0
</code></p>

<p>If everything finished successfully, typing <code>ruby -v</code> should output the Ruby version we now have installed.</p>

<h1>Installing Bundler</h1>

<p>If you’ve never used it before, <a href="http://bundler.io/">Bundler</a> is a tool that helps you easily manage and install gems (Ruby programs and libraries). It allows you to specify the gems your app relies on, along with their versions, and Bundler will then install them all for you, in addition to automatically installing and managing any dependencies (other gems) they rely on.</p>

<p>It’s usually a good idea to include version numbers for your gems because new versions can sometimes introduce changes that cause the old features you rely on to behave differently, which can result in errors the next time you try to run your app. By using Bundler to specify not only the gems you need, but also the versions of those gems, you can save yourself from needless headaches (and unnecessary cups of coffee).</p>

<p>We will install bundler with the following command:</p>

<p><code>bash
gem install bundler --no-ri --no-rdoc
</code></p>

<p>Every time we install a gem that provides us with commands we can execute, we’ll need to run <code>rbenv rehash</code>, which will give us access to the corresponding executable (<a href="http://stackoverflow.com/questions/9394338/how-do-rvm-and-rbenv-actually-work">see this page</a> to learn why this is so). Since Bundler is one of these gems, we’ll do the rehash next:</p>

<p><code>bash
rbenv rehash
</code></p>

<p>If things installed successfully, <code>bundle -v</code> should return the Bundler version that was just installed.</p>

<p>As an aside, notice that we’re specifying the <code>—no-ri</code> and <code>—no-rdoc</code> flags to avoid installing the gem’s documentation, which often takes longer than the gem installation itself and is typically unnecessary, especially on a production server. But typing out these flags for each and every gem you install will give you <a href="http://www.webmd.com/pain-management/carpal-tunnel/carpal-tunnel-syndrome-topic-overview">carpel tunnel</a> sooner than you&rsquo;d like, so its best to create a <code>.gemrc</code> file in your home directory:</p>

<p><code>bash
nano ~/.gemrc
</code></p>

<p>and add the following line into it:</p>

<p><code>text
gem: –no-ri –no-rdoc
</code></p>

<p>The flags will then be included automatically the next time you install new gems.</p>

<p>And with that, our server setup is now complete! Having installed Node.js, Nginx, PostgreSQL, and rbenv, we’re now ready to start configuring Nginx and Unicorn, which I’ll cover in the <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">next post</a>. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you’ll have the complete post delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 1: Securing the Server]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/"/>
    <updated>2014-03-05T11:18:00-08:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server</id>
    <content type="html"><![CDATA[<p>Setting up a Rails server from scratch can be a daunting task. I remember my first attempt; it was a multi-day process full of frustration, things not working, me not understanding why, and a whole lot of googling. In an effort to make this experience less painful for those new to Rails, I’d like to share the process I went through to deploy <a href="http://phindee.com/">Phindee</a> to a VPS (Virtual Private Server).</p>

<!-- more -->


<h1>Choosing a VPS</h1>

<p>Phindee is currently running on DigitalOcean servers, but there are other options available as well, like Linode, which was my previous VPS provider. If you’re new to deployment, I recommend <a href="http://digitalocean.com/">DigitalOcean</a> because it’ll be ideally suited to your needs, due their more flexible billing policy and cheaper plans, but any VPS provider will do.</p>

<p>Once you decide on a VPS, you’ll then signup for a plan. If you’re just starting out, the cheapest plan available will be enough; otherwise, choose a plan that fits your needs. Once you have an account, you’ll be able to create your server, and typically, you’ll have a list of operating systems to choose from. DigitalOcean offers a wide variety of Linux distributions; I chose the latest 32-bit version of Ubuntu for Phindee, and I recommend you do the same if you&rsquo;re new to deployment.</p>

<p>The reason why I chose the 32-bit version was because it uses less memory than the 64-bit one. This is something you should consider if you chose one of the cheaper plans with a lower amount of memory, but if memory is not an issue, go with the 64-bit since you’ll have better performance (<a href="howtoubuntu.org/how-to-decide-if-you-should-use-32bit-or-64bit-ubuntu">see this page</a> to learn more).</p>

<h1>Logging In</h1>

<p>Once you create your instance, you’ll be given your server’s IP address and password. If you’re on Linux or a Mac, open up Terminal and login. (If you&rsquo;re on Windows, you&rsquo;ll need to download Putty.) To login using Terminal, use the following command, replacing the Xs with your own IP address:</p>

<p><code>bash
ssh root@xxx.xxx.xxx.xxx
</code></p>

<p>This command uses SSH to connect to your server as the user <code>root</code>. If you’re unfamiliar with SSH, it stands for Secure Shell, and it’s basically a network protocol that allows two computers to securely communicate with one another. There are many other protocols out there, such as HTTP, which allows browsers to communicate with web servers.</p>

<p>The first time you attempt to login, you’ll be asked if you’re sure you want to continue connecting; type &ldquo;yes&rdquo;. Then enter the password for the <code>root</code> user, and you’ll be logged in.</p>

<h1>Groups and Privileges</h1>

<p>Now that you’re in, the first thing we’ll do is change the password for <code>root</code> using the following command:</p>

<p><code>bash
passwd
</code></p>

<p>This will prompt you to enter a new password twice. Next, we’ll create a new group called <code>deployers</code>, which will allow us to easily manage the users with deployment privileges:</p>

<p><code>bash
groupadd deployers
</code></p>

<p>Now we’ll create a new user called <code>bob</code>, and assign him to the <code>deployers</code> group we just created above:</p>

<p><code>bash
adduser bob —ingroup deployers
</code></p>

<p>This command will prompt you to enter a password for this user, in addition to some other information afterwards, but after you enter the password twice, feel free to just press “Enter” for the other fields, as they’re not strictly necessary. By the way, don’t use the same password for both <code>root</code> and the user you just created above or <a href="http://www.cartoonstock.com/lowres/computers-computer-self_destruct-explode-username-password-ksm0529l.jpg">bad things will happen</a>.</p>

<p>Next thing we’ll do is open the <code>sudoers</code> file containing a list of users and groups who have root privileges:</p>

<p><code>bash
nano /etc/sudoers
</code></p>

<p>and we’ll add the following line into it:</p>

<p><code>text sudoers
%deployers      ALL=(ALL) ALL
</code></p>

<p>You can then exit the nano text editor by typing &ldquo;Control-X&rdquo; and typing &ldquo;Y&rdquo; when asked if you want to save. In case you’re wondering, the line we just added above will give the users in the <code>deployers</code> group the ability to run commands as <code>root</code>. If this is new to you, I can explain.</p>

<p>Running commands while logged in as <code>root</code> is considered bad practice because, as the superuser, <code>root</code> can run any and all commands, and since there is no undo functionality in Unix, one accidental bad command and your system can be seriously disrupted. That’s why we created a separate user called <code>bob</code>, which will have deployment privileges and nothing else.</p>

<p>But why did we create a <code>deployers</code> group and added <code>bob</code> into it? Well, first of all, we could’ve avoided creating a group altogether and just added <code>bob</code> to the <code>sudoers</code> file and given <em>him</em> <code>root</code> privileges instead. But let’s say I’m working on a project with a friend and she wants to be able to deploy as well. I would have to then add her to the <code>sudoers</code> file too (to give her <code>root</code> privileges), and the file would keep growing every time a new user with deployment privileges needed to be added. This would be a nightmare to maintain.</p>

<p>A better way to go about this is to create a group called <code>deployers</code>, give the group <code>root</code> privileges, and then add users to this group. This way, whenever I’d need to add new users with deployment privileges, I would just need to add them to the <code>deployers</code> group. This keeps the <code>sudoers</code> file clean and organized, while allowing me to easily manage the members of the group as well. I could, for example, easily revoke some rights for all members of the <code>deployers</code> group at the same time, instead of doing it one user at a time, or I could simply remove a user from the <code>deployers</code> group if I discover, for example, that he still creates &ldquo;1234&rdquo; passwords for his accounts.</p>

<p>Okay, but why is it necessary for users and groups to have <code>root</code> privileges? Well, these privileges allow a user, say <code>bob</code>, to run commands he otherwise would not be able to run due to not having the necessary permissions, which arises from the fact that the user is not <code>root</code> and therefore has limited privileges. But given <code>root</code> privileges, or being part of a group with <code>root</code> privileges, enables <code>bob</code> to run these commands simply by preceding the command with <code>sudo</code>. He’ll then be prompted to enter his password, and the command will run.</p>

<p>That’s the reasoning behind giving the <code>deployers</code> group <code>root</code> privileges and adding <code>bob</code> into it. Later on, <code>bob</code> will need these privileges during the deployment process.</p>

<h1>Configuring SSH Access</h1>

<p>Now we’re ready for the next step in securing our server, and we’ll start by opening the <code>ssh_config</code> file:</p>

<p><code>bash
nano /etc/ssh/sshd_config
</code></p>

<p>This file contains a number of rules that define who can login to the server and in what way. The first thing we’ll do is change the port number with which users will login; the default port that servers listen on is 22, but it’s wise to change it to another value so that any potential hackers have some extra work to do in figuring out the correct one; you can choose any port number from 1025 to 65536. Once you have your number, look for a line that looks like the following:</p>

<p><code>text sshd_config
Port 22
</code></p>

<p>and change its port number to the one you picked. Make sure you make a note of the new port number because you’ll need it for future login.</p>

<p>Next, look for another line in the file that looks like this:</p>

<p><code>text sshd_config
PermitRootLogin yes
</code></p>

<p>and change the “yes” to a “no”; this prevents <code>root</code> user login, which means that any potential hackers will need to know the name of one of the users on the server to actually login.</p>

<p>We can even go a step further and define exactly which existing users are able to login. Since I only want <code>bob</code> to have login access, I’ll add the following line to the end of the file:</p>

<p><code>text sshd_config
AllowUsers bob
</code></p>

<p>You could even specify a space-separated list of users here, if you have more than one user in need of login access.</p>

<p>Alright, there is one final line that we’ll add to the end of our file:</p>

<p><code>text sshd_config
UseDNS no
</code></p>

<p>This line disables hostname lookup, which can lead to a delay of up to 30 seconds when logging in with <code>ssh</code>. Disabling it will save you time and do no harm.</p>

<p>To put these changes into effect, we’ll reload SSH, like so:</p>

<p><code>bash
/etc/init.d/sshd reload
</code></p>

<p>Now we’re ready to test the configurations we just made to make sure they work. I’ll open a new shell in Terminal, without closing my current one, and try to login as the user <code>bob</code> on the port I specified in <code>sshd_config</code>:</p>

<p><code>bash
ssh -p 23523 bob@xxx.xxx.xxx.xxx
</code></p>

<p>Make sure you change the above command to match the user and port number you specified in your own <code>sshd_config</code> file, or it obviously won’t work. The above command will then prompt you to enter that user’s password. If you login successfully, congratulations! Your configuration is correct! You can close your previous shell and just continue using the current one; otherwise, you’ll need to go back and double check your <code>sshd_config</code> file configurations.</p>

<h1>Enabling SSH Authentication</h1>

<p>The final thing we’ll do to secure our server is enable SSH authentication, which will allow us to use SSH keys to authenticate with the server, instead of the traditional password authentication. This is a more secure approach because password authentication involves sending your password over the network, and this makes it vulnerable to being intercepted and cracked. It’s also more convenient since you won’t need to enter it every time you want to login. But before we move on, I’d like to briefly explain how SSH keys work and what makes them more secure.</p>

<p>All SSH keys come in pairs: one private and the other public. The private key is stored locally and needs to be carefully guarded, while the public key is stored on the remote server to which you will be logging in. Anytime you want to connect to the server, it will use the public key to create a challenge, which it will then send over to you, and only you, the holder of the private key, will be able to correctly understand and solve the challenge. Your response is then sent back to the server, and if it’s correct, it’ll grant you access.</p>

<p>You can see if you already have an SSH key by running:</p>

<p><code>bash
ls ~/.ssh
</code></p>

<p>If you see any files with the <code>.pub</code> extension, then you already have a key generated; otherwise, you can generate one with the following command:</p>

<p><code>bash
ssh-keygen -C "your.email@example.com"
</code></p>

<p>Note that we&rsquo;re using the <code>-C</code> flag to create a label for our key for easy identification, and it&rsquo;s typical to set it to your email address. When the command runs, it’ll prompt you to enter a path and passphrase, but the default path is fine, and since we won’t be setting up a passphrase, you can just press “enter” for both. This will store both the private and public keys in the <code>~/.ssh/</code> directory, and they will be named according to the type of encryption used, the default being RSA authentication. Your private key will be stored in a file called <code>id_rsa</code>, while <code>id_rsa.pub</code> will hold your public key.</p>

<p>We&rsquo;ll then need to add the newly generated keys to <code>ssh-agent</code>, which is a program that caches your private key and provides it to the SSH client program on your behalf. You can do so with the following command:</p>

<p><code>bash
ssh-add ~/.ssh/id_rsa
</code></p>

<p>It&rsquo;ll then ask you for a passphrase, but since we didn&rsquo;t set one up, you&rsquo;ll just need to press &ldquo;enter.&rdquo;</p>

<p>Having our keys generated, we’re now ready to copy our public key over to the remote server using the <code>ssh-copy-id</code> command. (If you’re on a Mac, and you don’t have <code>ssh-copy-id</code> installed, you can install it using Homebrew with <code>brew install ssh-copy-id</code>.) Below is the full <code>ssh-copy-id</code> command that will copy our key over to the server:</p>

<p><code>bash
ssh-copy-id -i ~/.ssh/id_rsa.pub -p 23523 bob@xxx.xxx.xxx.xxx
</code></p>

<p>This will create a new file called <code>authorized_keys</code> on your remote server inside the <code>~/.ssh</code> directory and store your public key in it. If you now try to <code>ssh</code> into your server, you should be authenticated and logged in without entering your password.</p>

<p>Going through this process might seem a bit tedious and time consuming at first, but after you’ve done it a couple times, it will get easier and hopefully become second nature. Security is important, and the time you spend learning and implementing it is time well spent.</p>

<h1>Summary</h1>

<p>To summarize, we made our server more secure by:</p>

<ol>
<li>limiting <code>root</code> privileges to just members of the <code>deployers</code> group</li>
<li>setting a custom port with which to connect</li>
<li>disabling <code>root</code> login</li>
<li>specifying exactly which user is able to login</li>
<li>enabling SSH authentication</li>
</ol>


<p>Of course, this doesn’t mean our server is “unhackable” by any means, but it is significantly more secure than it was before. You can now sleep more peacefully knowing that any future hackers have at least some of their work cut out for them.</p>

<p>In <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, we’ll start setting up the server by installing the technology stack behind Phindee. If you’d like to be notified when its out, feel free to <a href="http://www.feedblitz.com/f/?sub=927939">subscribe</a>, and you&rsquo;ll get the complete post delivered right to your inbox as soon as it&rsquo;s released.</p>
]]></content>
  </entry>
  
</feed>
