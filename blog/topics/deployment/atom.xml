<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Topic: Deployment | Hungry and Foolish]]></title>
  <link href="http://vladigleba.github.io/blog/topics/deployment/atom.xml" rel="self"/>
  <link href="http://vladigleba.github.io/"/>
  <updated>2014-03-21T13:48:31-07:00</updated>
  <id>http://vladigleba.github.io/</id>
  <author>
    <name><![CDATA[Vladi Gleba]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 3: Configuring Nginx and Unicorn]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-nginx-and-unicorn/"/>
    <updated>2014-03-21T10:08:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-nginx-and-unicorn</id>
    <content type="html"><![CDATA[<p>Having covered how to install the technology stack powering Phindee in my <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">previous post</a>, I will now shift gears and explain how I configured Nginx and Unicorn. I already explained why I chose to install Nginx, but I haven’t yet explained why I chose Unicorn, so here we go.</p>

<!-- more -->


<h1>Unicorn and Passenger</h1>

<p>When I deployed Phindee for the first time, I actually used the open source version of <a href="https://www.phusionpassenger.com/">Phusion Passenger</a> due to the fact that it was (and is) easier to setup than Unicorn. My main concern, at the time, was to have a functioning app deployed as soon as possible, with as little effort as possible, and Passenger helped me do just that.</p>

<p>Eventually, I reached a point where I was ready for something that I could configure myself, and Unicorn seemed like a good next step. But if you’re a beginner, Passenger will be the easiest to start with since it’s designed to integrate into Nginx directly and, therefore, requires less work to setup and maintain. You will have to pay for the Enterprise version, however, if you want advanced features like error-resistant, zero-downtime deploys, which come for free with Unicorn.</p>

<h2>Do One Thing, Do It Well</h2>

<p>The reason why I like Unicorn is due to its philosophy of doing a few things well. An example of this is load balancing, which Unicorn hands off to the operating system entirely. When Unicorn starts, its master process spawns (forks) a configured number of processes called workers. These workers then handle the incoming requests to your app and only accept a request when they’re ready.</p>

<p>But it’s the operating system that handles the forking, as well as the distribution of requests between processes that are ready to accept, not Unicorn. What Unicorn does is the actual monitoring of workers themselves through the master process. If a worker, for example, takes too much time to complete a task, the master process will kill it and spawn a new one.</p>

<h2>Deploys Done Right</h2>

<p>What this design can achieve is error-resistant, zero-downtime deploys. Error-resistant deploys ensure that if something goes wrong during a deploy, your app will remain online and serve incoming requests using the old code. This is possible because Unicorn doesn’t kill off old workers until new workers have successfully forked, which means your old workers will stay alive if something goes wrong with the new ones.</p>

<p>Zero-downtime deploys work in a similar manner. We can send a signal to the master process telling it to start a new master, and this new master will then begin reloading our new code. Once it’s fully loaded, the new master will fork its workers. The first worker forked will notice there is still an old master running, and it’ll send a signal telling it to start gracefully shutting down its workers. When all workers finish serving their current requests, the old master then dies, and our app is fully reloaded with new code.</p>

<p>Passenger supports rolling restarts like this as well, but they only come with the paid Passenger Enterprise version. One advantage the Enterprise version provides, however, is it restarts the processes one-by-one, which requires less memory. Rolling restarts with Unicorn, on the other hand, are done all at once and temporarily require twice the memory usage. It is possible, of course, to script one-by-one rolling restarts in Unicorn, but Passenger does this automatically for you.</p>

<h1>Puma</h1>

<p>Another alternative to Unicorn and Passenger is Puma. Whereas Unicorn and Passenger achieve concurrency through the use of forks, Puma achieves it by running multiple threads in a single process. Of course, this means that your code must be thread-safe, but since Rails 4 is thread-safe by default, this shouldn’t be an issue.</p>

<p>Because threading requires less memory than forking, Puma will be more memory efficient than a similar Unicorn setup. Puma, however, does not do rolling restarts, nor does watch for and restart failed processes, like Unicorn, which means you’ll need a service like <a href="http://mmonit.com/monit/">Monit</a> that monitors and restarts them for you. As with any technology, pick whatever best meets your needs.</p>

<h1>Configuring Unicorn</h1>

<p>With that out of the way, we’re now ready to start configuring Unicorn. We’ll begin by adding the following line to our app’s <code>Gemfile</code>:</p>

<p><code>ruby Gemfile
gem 'unicorn', '~&gt; 4.8.0’
</code></p>

<p>Make sure you change the version number to whatever’s the most recent one at the time of your install. The <code>~&gt;</code> notation means that any future minor updates (e.g., from 4.0.0 to 4.0.1) will be installed, but major ones (e.g., from 4.0 to 4.1) won’t be. Major updates can sometimes introduce unexpected behavior in your app, so it’s best to limit the updates to minor releases only.</p>

<p>We can install Unicorn by running <code>bundle</code> in the root path of our app, and Bundler, which we installed in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, will take care of the install for us.</p>

<p>Having Unicorn installed, we can begin configuring it. We’ll start by creating a file called <code>unicorn.rb</code> on our local computer inside the <code>/config</code> directory of our Rails application. This is how my file for Phindee looks:</p>

<p>``` ruby unicorn.rb
root = “/var/www/phindee/current"
working_directory root
pid &ldquo;#{root}/tmp/pids/unicorn.pid&rdquo;
stderr_path &ldquo;#{root}/log/unicorn.log&rdquo;
stdout_path &ldquo;#{root}/log/unicorn.log&rdquo;</p>

<p>listen &ldquo;/tmp/unicorn.phindee.sock&rdquo;
worker_processes 2
timeout 30
```</p>

<p>The first variable <code>root</code> represents the path to the root directory, which is <code>/var/www/phindee/current</code> in my case. You can set this to whatever you like, but generally, web apps are often stored inside <code>/var/www</code> on Unix since the <code>/var</code> directory is designated for files that increase in size over time, and that’s the case with most web apps.</p>

<p>Below is what the rest of the configurations mean:</p>

<ul>
<li><p><code>working_directory</code> specifies exactly what is says&mdash;the app’s working directory&mdash; and it’s set to the variable <code>root</code>, which we just defined.</p></li>
<li><p><code>pid</code> specifies the path to a <code>.pid</code> file that will store the process ID of Unicorn’s master process, which can be later used to stop the process itself. These files are typically stored inside the <code>/tmp</code> directory since they exist only while Unicorn is running, so you can leave this line the way it is.</p></li>
<li><p><code>stderr_path</code> and <code>stdout_path</code> specify the path to <code>stderr</code> and <code>stdout</code>. If you’re not familiar with what they mean, when a Unix program starts up, it has three streams opened for it: one for input called “standard input” (abbreviated <code>stdin</code>), one for output called “standard output” (abbreviated <code>stdout</code>), and one for printing error messages called “standard error” (abbreviated <code>stderr</code>). Given our configuration, this means that any error messages written by our Rails app to the <code>stderr</code> stream will get written to the <code>.log</code> file specified in the <code>stderr_path</code>. It’s common to point <code>stdout_path</code> to the same location as <code>stderr_path</code> and store them both inside the <code>/log</code> directory.</p></li>
<li><p><code>listen</code> specifies the path to a socket that will listen for a client wanting to make a connection request. If you’re unfamiliar with this, a socket is basically a software object consisting of a port number that’s attached to an IP address. It allows clients and servers to communicate with one another by writing to and reading from their sockets. Since they’re running only when Unicorn is running, they’re usually stored inside the <code>/tmp</code> directory as well.</p></li>
<li><p><code>worker_processes</code> specifies the number of workers that the master process will fork for client request handling. The more workers you set, the more memory you’ll need, and since I don’t have a large amount of memory on my VPS, I decided to set mine to two. This should be enough for a low-traffic app, but once your traffic rises, the number of workers, as well as the amount of memory available to your server, will need to rise with it.</p></li>
<li><p><code>timeout</code> specifies the maximum number of seconds a worker can take to respond to a request before the master kills it and forks a new one. 30 seconds is a good value to put here since whenever a worker takes longer than this to respond, it’s usually safe to assume there is something wrong with the worker itself.</p></li>
</ul>


<p>You can get a complete list of all the other possible configuration options by taking a look Unicorn’s <a href="http://unicorn.bogomips.org/Unicorn/Configurator.html">Configurator Module</a>.</p>

<h1>Managing Unicorn Processes</h1>

<p>Having Unicorn configured, we’ll now need to setup a way for us to manage the Unicorn processes themselves.</p>

<p>Unicorn uses signals to communicate with its processes, and you can find a full explanation of all the available signals <a href="http://unicorn.bogomips.org/SIGNALS.html">here</a>. But sending these signals manually would be a pain. I recommend using a <a href="https://github.com/railscasts/335-deploying-to-a-vps/blob/master/blog-nginx/config/unicorn_init.sh">script on GitHub</a> to automate this process for you. Go ahead and create your own <code>unicorn_init.sh</code> file inside your app’s <code>/config</code> directory and copy/paste the script’s code into it. All the variables you can change are defined at the of the script, but for now, the only thing you’ll need to change is the <code>APP_ROOT</code> variable, which you’ll set to the same path that the <code>root</code> variable in <code>unicorn.rb</code> is set to.</p>

<p>If you’re inside the root directory of your Rails app, you can then make the script executable with the following command :</p>

<p><code>bash
chmod +x config/unicorn_init.sh
</code></p>

<p>I’d like to point out that the way <code>unicorn.rb</code> and <code>unicorn_init.sh</code> is currently setup, Unicorn won’t be doing rolling restarts. If you look at <code>unicorn_init.sh</code>, for example, you’ll notice that it sends a <code>HUP</code> signal when you run the script’s <code>restart</code> command. This signal doesn’t spawn a new master process, the way a rolling restart would do; it simply reloads the <code>unicorn.rb</code> file and gracefully restarts all the workers using the same master process.</p>

<p>You’d need to use the <code>USR2</code> signal for a rolling restart (which is actually what happens when you run the script’s <code>upgrade</code> command). But even then, there are still additional steps you’ll need to take to make everything runs smoothly, like making sure your database connections carry over, as well as ensuring any changes to the database are compatible with the older code.</p>

<p>I won’t be explaining how to do this here because I haven’t yet set it up myself, but if you’re curious, there is a good <a href="http://www.justinappears.com/blog/2-no-downtime-deploys-with-unicorn/">blog post</a> explaining all the nuances you need to be aware of. Phindee is currently a small, low-traffic app and its code is reloaded within seconds, so I’m not worried about users waiting for their requests and don’t see a need for rolling restarts at the moment, but I’m hoping the need presents itself soon.</p>

<h1>Configuring Nginx</h1>

<p>Having configured Unicorn, we can move on to configuring Nginx. We’ll start by creating a file called <code>nginx.conf</code> inside, as you might probably guess, the <code>/config</code> directory. Here’s how mine looks like:</p>

<p>``` nginx nginx.conf
worker_processes 1;</p>

<p>events {
  worker_connections 1024;
}</p>

<p>upstream unicorn {
  server unix:/tmp/unicorn.phindee.sock fail_timeout=0;
}</p>

<p>server {
  server_name www.phindee.com;
  return 301 $scheme://phindee.com$request_uri;
}</p>

<p>server {
  listen 80 default deferred;
  server_name phindee.com;
  root /var/www/phindee/current/public;</p>

<p> location ^~ /assets/ {</p>

<pre><code>gzip_static on;
expires max;
add_header Cache-Control public;
</code></pre>

<p>  }</p>

<p>  try_files $uri/index.html $uri @unicorn;
  location @unicorn {</p>

<pre><code>proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header Host $http_host;
proxy_redirect off;
proxy_pass http://unicorn;
</code></pre>

<p>  }</p>

<p>  error_page 500 502 503 504 /500.html;
  keepalive_timeout 5;
}
```</p>

<p>You might have noticed that the first thing we do is specify the number of workers to run. Sounds familiar, doesn’t it? Well, that’s because Nginx, like Unicorn, also has a master process managing all the workers, and the workers are the ones responsible for processing requests from clients. Unlike Unicorn, Nginx also has a cache loader process that checks and/or populates the cache with metadata, as well a cache manager process that’s responsible for cache expiration. Together, they keep Nginx internals running quickly and efficiently.</p>

<h2>A Bit on Workers</h2>

<p>As you can see, we used the <code>worker_processes</code> directive to tell Nginx to run one worker, which is the default. We then used the <code>worker_connections</code> directive inside the <code>events</code> block to specify that the maximum number of connections a worker can accept is 1024, which is also the default. Since we’re using defaults for both directives, it wasn’t necessary to add them to our file at all, but I chose to include them for completeness.</p>

<p>Given our current configuration, our server will be able to accept a total of 1024 simultaneous connections. If you want to increase this, it’s generally best to increase the <code>worker_connections</code> value before increasing the number of workers. Remember, each worker is a single-threaded process, so whenever you increase the number of workers, you’re also increasing the total amount of memory that will be used up. Having one worker process that’s capable of handling 1024 connections is more than enough for a low-traffic app, however.</p>

<h2>Hooking up with Unicorn and Handling Redirects</h2>

<p>Since Nginx is not capable of handling requests for pages that are dynamically generated by Rails, we need to tell it to somehow pass such requests off to Unicorn. We’ll take the first step to accomplishing this by defining an <code>upstream</code> block called <code>unicorn</code>, inside which we point the server to the same Unix socket that we used in our <code>unicorn.rb</code> file. This is just the first step, however, and more work needs to be done to get this working, as you’ll see later. By the way, in case you’re wondering, setting the <code>fail_timeout</code> to 0 is necessary for Nginx to correctly handle Unicorn timing out due to its worker being killed when it takes longer than 30 seconds to respond, as specified in <code>unicorn.rb</code>.</p>

<p>The <code>server</code> block right below the <code>upstream</code> block is there to redirect a request for &ldquo;www.phindee.com&rdquo; to &ldquo;phindee.com&rdquo;. The <code>server_name</code> directive specifies the URL we’re redirecting from, while the <code>return</code> directive specifies where to redirect to. (Notice we’re returning a 301 status code to specify a permanent redirection.) The <code>$scheme</code> variable stores the HTTP scheme (i.e. http, https), while <code>$request_uri</code> stores the unmodified URI of a client request, which includes the arguments, but not the host name (e.g. &ldquo;/foo/bar.php?arg=baz&rdquo;).</p>

<h2>Where the Meat Is</h2>

<p>The next <code>server</code> block contains the main configuration. The <code>listen</code> directive inside it tells Nginx to listen on port 80, and the <code>server_name</code> directive right below specifies the domain name that Nginx will try to match, which is &ldquo;phindee.com&rdquo; in my case.</p>

<p>Specifying <code>default</code> in the <code>listen</code> directive, by the way, tells Nginx to use this server block by default if it can’t find a matching domain name, which means I could technically leave out the <code>server_name</code> directive, and everything would still work because of <code>default</code>, but I like to leave it in for readability. And finally, I added the <code>deferred</code> option since I’m running this on Linux, which tells Nginx to use the <code>TCP_DEFER_ACCEPT</code> option to <a href="http://www.techrepublic.com/article/take-advantage-of-tcp-ip-options-to-optimize-data-transmission/">speed up performance</a> by reducing the amount of preliminary work that happens between a client and the server.</p>

<p>Moving along, the <code>root</code> directive specifies the directory in which Nginx will look to handle requests for static files. Note that this is <em>not</em> our app’s root directory, but our app’s <code>/public</code> directory, and this is where our static files are/will reside. Currently, it only contains various error pages, a favicon, and a <code>robots.txt</code> file for search engines. When we later deploy with Capistrano, it’ll contain all our assets as well, including stylesheets, scripts, images, and fonts.</p>

<h2>Handling Asset Requests</h2>

<p>Just like the <code>server_name</code> directive handles requests for domain names, the <code>location</code> directive handles requests for specific files and folders. The caret and tilde (<code>^~</code>) tells Nginx to do a regular expression match on <code>/assets/</code> and to stop searching as soon as it finds a match (see the <a href="https://library.linode.com/web-servers/nginx/configuration/basic#sph_location-file-and-folder-configuration">Linode Guide</a> to learn more).</p>

<p>By setting the <code>gzip_static</code> directive to <code>on</code>, we’re then telling Nginx to look for an already pre-compressed <code>.gz</code> file <em>before</em> proceeding to compress it. This prevents Nginx from compressing the same file each time it is requested.</p>

<p>The <code>expires</code> directive then makes the response cacheable and marks it with an expiry date set to <code>max</code>, which is equivalent to December 31st, 2037. This tells browsers and any caching servers to not request these assets again until the specified date. Of course, if we make changes to our stylesheets, for example, Rails will change the filename and browsers will still receive the latest version, which will then also be cached.</p>

<p>Using the <code>expires</code> directive, however, is an outdated method of specifying caching, and it’s recommended to use <code>Cache-Control</code> header instead. The next line in the code does just that through the <code>add_header</code> directive. (The reason we include  <code>expires</code> is to make things backward-compatible.) It’s possible, by the way, to set <code>Cache-Control</code> to either <code>public</code> or <code>private</code>, and I’m setting it to <code>public</code> because we’re caching assets that are meant to be used by everybody, whereas <code>private</code> would mean they’re unique to individual users (see <a href="http://stackoverflow.com/questions/3492319/private-vs-public-in-cache-control">Stack Overflow</a> to learn more).</p>

<h2>Trying to Find a Match</h2>

<p>The next line is the <code>try_files</code> directive, which is there for requests that didn’t match with any <code>location</code> blocks. In our case, it tries to match non-asset requests. The <code>$uri</code> variable contains the current request URI, minus the arguments, protocol, and host name, so if we typed in &ldquo;phindee.com/assets&rdquo; into the address bar, the <code>$uri</code> would be &ldquo;/assets&rdquo;, and given our <code>try_files</code> directive, Nginx would try to first find an <code>/assets/index.html</code> file. If it found no such file, it would then try to find an <code>/assets</code> directory, and if that wouldn’t exist, it would then pass the request off to Unicorn through a named location, which is defined next through the <code>location</code> directive and called <code>@unicorn</code>.</p>

<p>Inside the named location, the <code>proxy_pass</code> directive does all the heavy lifting. We set it to <code>http://unicorn</code> so that it points to the <code>upstream</code> block called <code>unicorn</code>, which we already defined, and the request is then handled by the Unicorn socket defined there. The two <code>proxy_set_header</code> directives then append additional headers needed for Unicorn, while <code>proxy_redirect</code> set to <code>off</code> prevents Nginx from doing any redirect handling. (There is a sample <code>nginx.conf</code> file <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">on GitHub</a> with comments explaining why this is necessary.)</p>

<h2>Last Few Lines</h2>

<p>Alright, we’re down to the last two lines. <code>error_page</code> makes sure that our app’s <code>500.html</code> page is show for any 500-related errors, while <code>keepalive_timeout</code> tells Nginx to retain keep-alive connections (also known as persistent connections) for up to 10 seconds and close them if they exceed that time.</p>

<p>Persistent connections, by the way, are used to send multiple HTTP requests in a single connection, as opposed to opening a new connection for each request; in HTTP 1.1, all connections are persistent by default, which means stylesheets, scripts, images, and fonts, for example, would all be downloaded using a single connection.</p>

<p>These are, of course, not all the options you can specify. If you’d like to learn about the additional ones, feel free to read through the comments in the sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file</a> I mentioned earlier.</p>

<h1>That Was Long</h1>

<p>I didn’t expect the post to be quite this long, and if you made all the way to the end, pat yourself on the back. But I personally love posts that explain the reasoning behind their decisions, and I tried to do the same here. I think it prepares readers to be able to make their own informed decisions in their own projects.</p>

<p>In the next and final post of this series, I will introduce Capistrano and show you how I use it to deploy Phindee to my VPS. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and the post will be delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 2: Setting up the Server]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/"/>
    <updated>2014-03-14T09:45:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server</id>
    <content type="html"><![CDATA[<p>In <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>, I talked about choosing a VPS provider, creating a new Ubuntu instance, and configuring it to be more secure. Now, in part 2, I&rsquo;ll talk about installing the technology stack behind <a href="http://phindee.com/">Phindee</a>: Node.js, Nginx, PostgreSQL, rbenv, Ruby, and Bundler.</p>

<!-- more -->


<h1>But First!</h1>

<p>Before we proceed any further, make sure you’re logged in as the user you created in part 1; if you’re already logged in as <code>root</code>, you can switch to the correct user with the following command:</p>

<p><code>bash
su - username
</code></p>

<p>Once logged in, we’ll run the following command to fetch the latest updates for the packages on our system:</p>

<p><code>bash
sudo apt-get update
</code></p>

<p>We’ll follow this up with the command to install the necessary package updates:</p>

<p><code>bash
sudo apt-get upgrade
</code></p>

<p>If the command found any updates to install, it will ask if you want to continue with the install; you can enter “y” to do so. Once it finishes, we’ll be ready begin.</p>

<h1>Setting Timezones and Installing Mail</h1>

<p>We’ll start by setting the correct timezone:</p>

<p><code>bash
sudo dpkg-reconfigure tzdata
</code></p>

<p>You’ll be asked to choose your country and timezone, after which your server’s local time will be displayed; if it displays the correct time, you’re good to go.</p>

<p>We’ll install <code>postfix</code> and <code>telnet</code> next to enable our Rails app to send email:</p>

<p><code>bash
sudo apt-get -y install telnet postfix
</code></p>

<p>Feel free to just press “enter” through all the prompts and keep all the defaults.</p>

<p>Next, we’ll install some useful packages we’ll later need, among them <code>python-software-properties</code>, which will allow us to easily add new repositories to the <code>apt</code> package handling system:</p>

<p><code>bash
sudo apt-get -y install curl git-core python-software-properties
</code></p>

<p>Having the ability to add new repositories this way allows us to install the most recent updates since the default <code>apt-get</code> repositories typically don’t receive the latest updates immediately.</p>

<h1>Installing Node.js</h1>

<p>We’ll actually put this ability to use right now by adding a new repository for <a href="http://nodejs.org/">Node.js</a>:</p>

<p><code>bash
sudo add-apt-repository ppa:chris-lea/node.js
</code></p>

<p>We’ll then update the created repository with the latest Node.js code available:</p>

<p><code>bash
sudo apt-get -y update
</code></p>

<p>and install it, like so:</p>

<p><code>bash
sudo apt-get -y install nodejs
</code></p>

<p>We could’ve avoided adding a new repo and just used the traditional <code>apt-get</code> method to do the install, but this would’ve installed an older version of Node.js. Because Node.js is under active development and things are added quite frequently, it’s important to run the latest possible version. This might not matter as much for software that doesn’t have an aggressive update schedule, but this is the route we’ll take for Node.js.</p>

<p>By the way, if you’re wondering why we’re installing Node.js, the reason is it provides a good way to execute JavaScript, and we’ll need this for the Rails <a href="http://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>.</p>

<h1>Installing Nginx</h1>

<p>Next, we’ll install a web server called <a href="http://wiki.nginx.org/Main">Nginx</a>, which will handle all our static requests, such as stylesheets, scripts, images, and fonts. Its low memory usage and ability to serve static content quickly and efficiently make it a popular alternative to Apache and an excellent choice for sites running on a Virtual Private Server (VPS). What makes Nginx efficient is the fact that it’s an event-based server, while Apache, on the other hand, is process-based. An event-based server doesn&rsquo;t spawn new processes or threads for each request the way a process-based one does, and this means lower memory usage and faster responses.</p>

<p>We’ll install it by adding another repository:</p>

<p><code>bash
sudo add-apt-repository ppa:nginx/stable
sudo apt-get -y update
sudo apt-get -y install nginx
</code></p>

<p>Once it’s installed, we can start it up with:</p>

<p><code>bash
sudo service nginx start
</code></p>

<p>If you now visit your server’s IP address, you should see a simple page proclaiming “Welcome to nginx!”</p>

<h1>Installing PostgreSQL</h1>

<p>Most modern apps need to store some sort of data, and there are a plethora of open source databases available, like <a href="https://www.mysql.com/">MySQL</a>, <a href="https://sqlite.org/">SQLite</a>, and <a href="http://www.postgresql.org/">PostgreSQL</a>. I never tried MySQL, but when I first started out, I used SQLite, the default database for Rails apps, because I liked its simplicity and saw no need for something more sophisticated. As my needs have evolved, however, so has my database, and I recently decided to switch to PostgreSQL because of its support for a fast key-value store called HStore and its ability to do full-text search, both of which I&rsquo;ll need for Phindee.</p>

<p>We’ll install it with <code>apt-get</code>:</p>

<p><code>bash
sudo apt-get install postgresql postgresql-contrib
</code></p>

<p>We can then start Postgres as the default <code>postgres</code> user with the following command:</p>

<p><code>bash
sudo -u postgres psql
</code></p>

<p>Had we not specified the default user, it would’ve tried to use the user we’re logged in with on our VPS, and Postgres would’ve complained that the role doesn’t exist since there is no such user created in Postgres. This makes it necessary to login as the default <code>postgres</code> user.</p>

<p>Once logged in, we’ll setup a password for <code>postgres</code>:</p>

<p><code>sql
\password
</code></p>

<p>We’ll also create a new user called <code>admin</code>, followed by a database called <code>phindee</code>, which will be owned by <code>admin</code>:</p>

<p><code>sql
create user admin with password 'secret';
create database phindee owner admin;
</code></p>

<p>Having the basics setup, we can now quit Postgres:</p>

<p><code>sql
\quit
</code></p>

<h1>Installing rbenv</h1>

<p><a href="https://github.com/sstephenson/rbenv">rbenv</a> is a tool that helps you manage the Ruby versions installed on your system, thereby allowing you to easily switch between them. Whenever you want to play with a new version of Rails&mdash;without messing up your current setup&mdash;rbenv will come in handy.</p>

<p>You may be familiar with another Ruby version manager called <a href="https://rvm.io/">RVM</a>. I used it myself for a while, before switching over to rbenv. It’s not that one is “better” than the other; it’s about which one is better suited for <em>your</em> needs. I made the switch because rbenv is more lightweight than RVM, its design feels cleaner, and it has a cool name.</p>

<p>rbenv will suite you well if you’re starting out; otherwise, install whatever best meets your needs. By the way, it’s worth mentioning that since rbenv is incompatible with RVM, you won’t be able to run them side by side.</p>

<p>Alright, we can install rbenv like so:</p>

<p><code>bash
sudo curl -L https://raw.github.com/fesplugas/rbenv-installer/master/bin/rbenv-installer | bash
</code></p>

<p>This will run a script that will do most of the install for us. In the end, you’ll receive a message telling you to add rbenv to the load path, and you can do so by opening up <code>bash_profile</code>:</p>

<p><code>bash
sudo nano ~/.bash_profile
</code></p>

<p>and copying/pasting the code that was outputted by the message. We’ll then need to reload the file for the changes to take effect:</p>

<p><code>bash
. ~/.bash_profile
</code></p>

<p>We’re almost ready to install Ruby, but before we do, we first need to install the C compiler and the Make utility, which is needed for the Ruby install. We can do so by installing a package called <code>build-essential</code>, along with some additional packages we’ll need later on:</p>

<p><code>bash
sudo apt-get install zlib1g-dev build-essential libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libpq-dev
</code></p>

<p>With the packages installed, we’re now ready to install Ruby itself.</p>

<h1>Installing Ruby</h1>

<p>To see a list of all the Ruby versions available, we can run the following command:</p>

<p><code>bash
rbenv install --list
</code></p>

<p>I chose to install version 2.1.0, as that was the latest one at the time:</p>

<p><code>bash
rbenv install 2.1.0
</code></p>

<p>This will take a few minutes to run&mdash;and that’s probably an understatement&mdash;but once it finishes, we’ll make the version it just installed the default Ruby version on our server:</p>

<p><code>bash
rbenv global 2.1.0
</code></p>

<p>If everything finished successfully, typing <code>ruby -v</code> should output the Ruby version we now have installed.</p>

<h1>Installing Bundler</h1>

<p>If you’ve never used it before, <a href="http://bundler.io/">Bundler</a> is a tool that helps you easily manage and install gems (Ruby programs and libraries). It allows you to specify the gems your app relies on, along with their versions, and Bundler will then install them all for you, in addition to automatically installing and managing any dependencies (other gems) they rely on.</p>

<p>It’s usually a good idea to include version numbers for your gems because new versions can sometimes introduce changes that cause the old features you rely on to behave differently, which can result in errors the next time you try to run your app. By using Bundler to specify not only the gems you need, but also the versions of those gems, you can save yourself from needless headaches (and unnecessary cups of coffee).</p>

<p>We will install bundler with the following command:</p>

<p><code>bash
gem install bundler --no-ri --no-rdoc
</code></p>

<p>Every time we install a gem that provides us with commands we can execute, we’ll need to run <code>rbenv rehash</code>, which will give us access to the corresponding executable (<a href="http://stackoverflow.com/questions/9394338/how-do-rvm-and-rbenv-actually-work">see this page</a> to learn why this is so). Since Bundler is one of these gems, we’ll do the rehash next:</p>

<p><code>bash
rbenv rehash
</code></p>

<p>If things installed successfully, <code>bundle -v</code> should return the Bundler version that was just installed.</p>

<p>As an aside, notice that we’re specifying the <code>—no-ri</code> and <code>—no-rdoc</code> flags to avoid installing the gem’s documentation, which often takes longer than the gem installation itself and is typically unnecessary, especially on a production server. But typing out these flags for each and every gem you install will give you <a href="http://www.webmd.com/pain-management/carpal-tunnel/carpal-tunnel-syndrome-topic-overview">carpel tunnel</a> sooner than you&rsquo;d like, so its best to create a <code>.gemrc</code> file in your home directory:</p>

<p><code>bash
nano ~/.gemrc
</code></p>

<p>and add the following line into it:</p>

<p><code>text
gem: –no-ri –no-rdoc
</code></p>

<p>The flags will then be included automatically the next time you install new gems.</p>

<p>And with that, our server setup is now complete! Having installed Node.js, Nginx, PostgreSQL, and rbenv, we’re now ready to start configuring Nginx and Unicorn, which I’ll cover in the <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-nginx-and-unicorn/">next post</a>. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you’ll have the complete post delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 1: Securing the Server]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/"/>
    <updated>2014-03-05T11:18:00-08:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server</id>
    <content type="html"><![CDATA[<p>Setting up a Rails server from scratch can be a daunting task. I remember my first attempt; it was a multi-day process full of frustration, things not working, me not understanding why, and a whole lot of googling. In an effort to make this experience less painful for those new to Rails, I’d like to share the process I went through to deploy <a href="http://phindee.com/">Phindee</a> to a VPS (Virtual Private Server).</p>

<!-- more -->


<h1>Choosing a VPS</h1>

<p>Phindee is currently running on DigitalOcean servers, but there are other options available as well, like Linode, which was my previous VPS provider. If you’re new to deployment, I recommend <a href="http://digitalocean.com/">DigitalOcean</a> because it’ll be ideally suited to your needs, due their more flexible billing policy and cheaper plans, but any VPS provider will do.</p>

<p>Once you decide on a VPS, you’ll then signup for a plan. If you’re just starting out, the cheapest plan available will be enough; otherwise, choose a plan that fits your needs. Once you have an account, you’ll be able to create your server, and typically, you’ll have a list of operating systems to choose from. DigitalOcean offers a wide variety of Linux distributions; I chose the latest 32-bit version of Ubuntu for Phindee, and I recommend you do the same if you&rsquo;re new to deployment.</p>

<p>The reason why I chose the 32-bit version was because it uses less memory than the 64-bit one. This is something you should consider if you chose one of the cheaper plans with a lower amount of memory, but if memory is not an issue, go with the 64-bit since you’ll have better performance (<a href="howtoubuntu.org/how-to-decide-if-you-should-use-32bit-or-64bit-ubuntu">see this page</a> to learn more).</p>

<h1>Logging In</h1>

<p>Once you create your instance, you’ll be given your server’s IP address and password. If you’re on Linux or a Mac, open up Terminal and login. (If you&rsquo;re on Windows, you&rsquo;ll need to download Putty.) To login using Terminal, use the following command, replacing the Xs with your own IP address:</p>

<p><code>bash
ssh root@xxx.xxx.xxx.xxx
</code></p>

<p>This command uses SSH to connect to your server as the user <code>root</code>. If you’re unfamiliar with SSH, it stands for Secure Shell, and it’s basically a network protocol that allows two computers to securely communicate with one another. There are many other protocols out there, such as HTTP, which allows browsers to communicate with web servers.</p>

<p>The first time you attempt to login, you’ll be asked if you’re sure you want to continue connecting; type &ldquo;yes&rdquo;. Then enter the password for the <code>root</code> user, and you’ll be logged in.</p>

<h1>Groups and Privileges</h1>

<p>Now that you’re in, the first thing we’ll do is change the password for <code>root</code> using the following command:</p>

<p><code>bash
passwd
</code></p>

<p>This will prompt you to enter a new password twice. Next, we’ll create a new group called <code>deployers</code>, which will allow us to easily manage the users with deployment privileges:</p>

<p><code>bash
groupadd deployers
</code></p>

<p>Now we’ll create a new user called <code>bob</code>, and assign him to the <code>deployers</code> group we just created above:</p>

<p><code>bash
adduser bob —ingroup deployers
</code></p>

<p>This command will prompt you to enter a password for this user, in addition to some other information afterwards, but after you enter the password twice, feel free to just press “Enter” for the other fields, as they’re not strictly necessary. By the way, don’t use the same password for both <code>root</code> and the user you just created above or <a href="http://www.cartoonstock.com/lowres/computers-computer-self_destruct-explode-username-password-ksm0529l.jpg">bad things will happen</a>.</p>

<p>Next thing we’ll do is open the <code>sudoers</code> file containing a list of users and groups who have root privileges:</p>

<p><code>bash
nano /etc/sudoers
</code></p>

<p>and we’ll add the following line into it:</p>

<p><code>text sudoers
%deployers      ALL=(ALL) ALL
</code></p>

<p>You can then exit the nano text editor by typing &ldquo;Control-X&rdquo; and typing &ldquo;Y&rdquo; when asked if you want to save. In case you’re wondering, the line we just added above will give the users in the <code>deployers</code> group the ability to run commands as <code>root</code>. If this is new to you, I can explain.</p>

<p>Running commands while logged in as <code>root</code> is considered bad practice because, as the superuser, <code>root</code> can run any and all commands, and since there is no undo functionality in Unix, one accidental bad command and your system can be seriously disrupted. That’s why we created a separate user called <code>bob</code>, which will have deployment privileges and nothing else.</p>

<p>But why did we create a <code>deployers</code> group and added <code>bob</code> into it? Well, first of all, we could’ve avoided creating a group altogether and just added <code>bob</code> to the <code>sudoers</code> file and given <em>him</em> <code>root</code> privileges instead. But let’s say I’m working on a project with a friend and she wants to be able to deploy as well. I would have to then add her to the <code>sudoers</code> file too (to give her <code>root</code> privileges), and the file would keep growing every time a new user with deployment privileges needed to be added. This would be a nightmare to maintain.</p>

<p>A better way to go about this is to create a group called <code>deployers</code>, give the group <code>root</code> privileges, and then add users to this group. This way, whenever I’d need to add new users with deployment privileges, I would just need to add them to the <code>deployers</code> group. This keeps the <code>sudoers</code> file clean and organized, while allowing me to easily manage the members of the group as well. I could, for example, easily revoke some rights for all members of the <code>deployers</code> group at the same time, instead of doing it one user at a time, or I could simply remove a user from the <code>deployers</code> group if I discover, for example, that he still creates &ldquo;1234&rdquo; passwords for his accounts.</p>

<p>Okay, but why is it necessary for users and groups to have <code>root</code> privileges? Well, these privileges allow a user, say <code>bob</code>, to run commands he otherwise would not be able to run due to not having the necessary permissions, which arises from the fact that the user is not <code>root</code> and therefore has limited privileges. But given <code>root</code> privileges, or being part of a group with <code>root</code> privileges, enables <code>bob</code> to run these commands simply by preceding the command with <code>sudo</code>. He’ll then be prompted to enter his password, and the command will run.</p>

<p>That’s the reasoning behind giving the <code>deployers</code> group <code>root</code> privileges and adding <code>bob</code> into it. Later on, <code>bob</code> will need these privileges during the deployment process.</p>

<h1>Configuring SSH Access</h1>

<p>Now we’re ready for the next step in securing our server, and we’ll start by opening the <code>ssh_config</code> file:</p>

<p><code>bash
nano /etc/ssh/sshd_config
</code></p>

<p>This file contains a number of rules that define who can login to the server and in what way. The first thing we’ll do is change the port number with which users will login; the default port that servers listen on is 22, but it’s wise to change it to another value so that any potential hackers have some extra work to do in figuring out the correct one; you can choose any port number from 1025 to 65536. Once you have your number, look for a line that looks like the following:</p>

<p><code>text sshd_config
Port 22
</code></p>

<p>and change its port number to the one you picked. Make sure you make a note of the new port number because you’ll need it for future login.</p>

<p>Next, look for another line in the file that looks like this:</p>

<p><code>text sshd_config
PermitRootLogin yes
</code></p>

<p>and change the “yes” to a “no”; this prevents <code>root</code> user login, which means that any potential hackers will need to know the name of one of the users on the server to actually login.</p>

<p>We can even go a step further and define exactly which existing users are able to login. Since I only want <code>bob</code> to have login access, I’ll add the following line to the end of the file:</p>

<p><code>text sshd_config
AllowUsers bob
</code></p>

<p>You could even specify a space-separated list of users here, if you have more than one user in need of login access.</p>

<p>Alright, there is one final line that we’ll add to the end of our file:</p>

<p><code>text sshd_config
UseDNS no
</code></p>

<p>This line disables hostname lookup, which can lead to a delay of up to 30 seconds when logging in with <code>ssh</code>. Disabling it will save you time and do no harm.</p>

<p>To put these changes into effect, we’ll reload SSH, like so:</p>

<p><code>bash
/etc/init.d/sshd reload
</code></p>

<p>Now we’re ready to test the configurations we just made to make sure they work. I’ll open a new shell in Terminal, without closing my current one, and try to login as the user <code>bob</code> on the port I specified in <code>sshd_config</code>:</p>

<p><code>bash
ssh -p 23523 bob@xxx.xxx.xxx.xxx
</code></p>

<p>Make sure you change the above command to match the user and port number you specified in your own <code>sshd_config</code> file, or it obviously won’t work. The above command will then prompt you to enter that user’s password. If you login successfully, congratulations! Your configuration is correct! You can close your previous shell and just continue using the current one; otherwise, you’ll need to go back and double check your <code>sshd_config</code> file configurations.</p>

<h1>Enabling SSH Authentication</h1>

<p>The final thing we’ll do to secure our server is enable SSH authentication, which will allow us to use SSH keys to authenticate with the server, instead of the traditional password authentication. This is a more secure approach because password authentication involves sending your password over the network, and this makes it vulnerable to being intercepted and cracked. It’s also more convenient since you won’t need to enter it every time you want to login. But before we move on, I’d like to briefly explain how SSH keys work and what makes them more secure.</p>

<p>All SSH keys come in pairs: one private and the other public. The private key is stored locally and needs to be carefully guarded, while the public key is stored on the remote server to which you will be logging in. Anytime you want to connect to the server, it will use the public key to create a challenge, which it will then send over to you, and only you, the holder of the private key, will be able to correctly understand and solve the challenge. Your response is then sent back to the server, and if it’s correct, it’ll grant you access.</p>

<p>If you don’t already have an SSH key, you can generate it with the following command:</p>

<p><code>bash
ssh-keygen
</code></p>

<p>It’ll prompt you to enter a path and passphrase, but the default path is fine, and since we won’t be setting up a passphrase, you can just press “enter” for both. This will store both the private and public keys in the <code>~/.ssh/</code> directory, and they will be named according to the type of encryption used, the default being RSA authentication. Your private key will be stored in a file called <code>id_rsa</code>, while <code>id_rsa.pub</code> will hold your public key.</p>

<p>Having our keys generated, we’re now ready to copy our public key over to the remote server using the <code>ssh-copy-id</code> command. (If you’re on a Mac, and you don’t have <code>ssh-copy-id</code> installed, you can install it using Homebrew with <code>brew install ssh-copy-id</code>.) Below is the full <code>ssh-copy-id</code> command that will copy our key over to the server:</p>

<p><code>bash
ssh-copy-id -i ~/.ssh/id_rsa.pub -p 23523 bob@xxx.xxx.xxx.xxx
</code></p>

<p>This will create a new file called <code>authorized_keys</code> on your remote server inside the <code>~/.ssh</code> directory and store your public key in it. If you now try to <code>ssh</code> into your server, you should be authenticated and logged in without entering your password.</p>

<p>Going through this process might seem a bit tedious and time consuming at first, but after you’ve done it a couple times, it will get easier and hopefully become second nature. Security is important, and the time you spend learning and implementing it is time well spent.</p>

<h1>Summary</h1>

<p>To summarize, we made our server more secure by:</p>

<ol>
<li>limiting <code>root</code> privileges to just members of the <code>deployers</code> group</li>
<li>setting a custom port with which to connect</li>
<li>disabling <code>root</code> login</li>
<li>specifying exactly which user is able to login</li>
<li>enabling SSH authentication</li>
</ol>


<p>Of course, this doesn’t mean our server is “unhackable” by any means, but it is significantly more secure than it was before. You can now sleep more peacefully knowing that any future hackers have at least some of their work cut out for them.</p>

<p>In <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, we’ll start setting up the server by installing the technology stack behind Phindee. If you’d like to be notified when its out, feel free to <a href="http://www.feedblitz.com/f/?sub=927939">subscribe</a>, and you&rsquo;ll get the complete post delivered right to your inbox as soon as it&rsquo;s released.</p>

<p>Stay hungry. Stay foolish.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I'm Leaving Linode for DigitalOcean]]></title>
    <link href="http://vladigleba.github.io/blog/2014/02/27/im-leaving-linode-for-digitalocean/"/>
    <updated>2014-02-27T08:16:00-08:00</updated>
    <id>http://vladigleba.github.io/blog/2014/02/27/im-leaving-linode-for-digitalocean</id>
    <content type="html"><![CDATA[<p>A few weeks ago, I ran into a <a href="http://blog.schneidmaster.com/digital-ocean-vs-linode/">blog post</a> (and the resulting <a href="https://news.ycombinator.com/item?id=7021664">Hacker News discussion</a>) comparing two popular VPS providers: <a href="https://www.linode.com/">Linode</a> and <a href="https://www.digitalocean.com/">DigitalOcean</a>. Up until that point, I was a happy Linode customer for over two years. I had heard about DigitalOcean previously, but never considered trying it since I was happy with Linode. This post, however, intrigued me enough to try DigitalOcean out.</p>

<!-- more -->


<p>Fast forward to today and <a href="http://www.phindee.com/">Phindee</a> is now running on DigitalOcean servers!</p>

<h1>What’s so Cool about DigitalOcean?</h1>

<p>I was drawn to DigitalOcean due to one killer feature, and I would&rsquo;ve moved because of this one feature alone: their billing policy. Let me explain.</p>

<h2>Flexible Billing</h2>

<p>When you create a new instance with Linode, you’re immediately charged for the entire month; if you then decide to destroy that instance a few days later, Linode will return a large portion of that month’s payment as Linode credit. With DigitalOcean, however, you’re only charged for what you use&mdash;no more, no less&mdash;so if you spin up an instance and decide to delete it the next day, you’ll be charged only for those few hours you used up.</p>

<p>I’ve lost track of the number of instances I’ve temporarily spun up since switching over to DigitalOcean three weeks ago, but I can count the number of times I did this with Linode on one of my two hands. The benefits of this flexibility are obvious: higher incentive to experiment with new technologies, test prototypes, and tinker with new ideas.</p>

<p>But that’s not all.</p>

<h2>Lower Starter Plan</h2>

<p>Besides flexible billing, I also like DigitalOcean’s plans, which I find to be perfect for apps with small amounts of traffic. Linode’s plans start at $20 a month and paying that much to host apps that receive less than 500 visits a month seemed a little ridiculous to me.</p>

<p>DigitalOcean’s plans start at $5 a month, which gives you 512MB of memory, a 20GB SSD disk, and 1TB of transfer. Linode’s basic $20 a month plan gives you 1024MB of RAM, a 48GB disk, and 2TB of transfer, which is similar to DigitalOcean’s $10 plan. In effect, DigitalOcean offers the same thing at half the price, and this carries over to the more expensive plans as well.</p>

<p>In effect, Linode’s starter plan seemed a bit overkill for my low traffic apps, while DigitalOcean suited them perfectly, so my choice was easy.</p>

<h1>Credit Where It&rsquo;s Due</h1>

<p>This post, however, would not be complete if I didn’t give credit where it’s due.</p>

<p>During my two years with Linode, I experienced absolutely no down-time; I think this speaks volumes to the quality of their products. I also want to mention their excellent <a href="https://library.linode.com/">library of guides</a>, which I found to be an invaluable resource whenever I needed help configuring my server.</p>

<p>But perhaps the thing their known for the most is their excellent customer service. Although I never had a need to contact support, I’ve only heard good things from other people, and some developers choose Linode solely due to their outstanding customer service.</p>

<p>Now in the interests of fairness, I should mention that Linode’s security record <a href="https://blog.linode.com/2013/04/16/security-incident-update/">is not spotless</a>, and they have been criticized for the way they handled some of their breaches, but I find this to be the exception rather than the norm. As long as this is a rare occurrence, Linode’s other pros outweigh this con.</p>

<p>Make no mistake, I’m leaving as a happy customer who was merely tempted and eventually won over by DigitalOcean’s flexible billing and a lower starter plan. I will have no hesitation coming back if the need arises.</p>

<h1>A Word About Future Posts</h1>

<p>Now that I’ve successfully moved Phindee over to DigitalOcean, I will use the next four posts to show you how I went about deploying Phindee from scratch. This is how I&rsquo;ll break it down:</p>

<ul>
<li><a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">Deploying Rails Apps, Part 1: Securing the Server</a></li>
<li><a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">Deploying Rails Apps, Part 2: Setting up the Server</a></li>
<li><a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-nginx-and-unicorn/">Deploying Rails Apps, Part 3: Configuring Nginx and Unicorn</a></li>
<li>Deploying Rails Apps, Part 4: Configuring Capistrano</li>
</ul>


<p>I plan on publishing one part per week, starting with <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a> next week. If you&rsquo;d like to be notified when a post is out, feel free to <a href="http://www.feedblitz.com/f/?sub=927939">subscribe</a>, and you&rsquo;ll get the complete post delivered right to your inbox as soon as it&rsquo;s out!</p>
]]></content>
  </entry>
  
</feed>
